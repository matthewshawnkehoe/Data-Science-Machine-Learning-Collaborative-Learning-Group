{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the `requirements.txt` for this course from the workspace of this lab. `File --> Open...`\n",
    "\n",
    "Course Website: https://learn.deeplearning.ai/courses/quantization-fundamentals/lesson/1/introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8teiBZ6dP5g"
   },
   "source": [
    "# Lesson 2: Data Types and Sizes\n",
    "\n",
    "In this lab, you will learn about the common data types used to store the parameters of machine learning models.\n",
    "\n",
    "\n",
    "The libraries are already installed in the classroom.  If you're running this notebook on your own machine, you can install the following:\n",
    "\n",
    "```Python\n",
    "!pip install torch==2.1.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30,
    "id": "x_9J8WavkQGl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "height": 30,
    "id": "nFC9wgzxBZvz"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW7psx41rn0h"
   },
   "source": [
    "### Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=0, max=255, dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information of `8-bit unsigned integer`\n",
    "torch.iinfo(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-128, max=127, dtype=int8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information of `8-bit (signed) integer`\n",
    "torch.iinfo(torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-9.22337e+18, max=9.22337e+18, dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Information of `64-bit (signed) integer`\n",
    "torch.iinfo(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-2.14748e+09, max=2.14748e+09, dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Information of `32-bit (signed) integer`\n",
    "torch.iinfo(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-32768, max=32767, dtype=int16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Information of `16-bit (signed) integer`\n",
    "torch.iinfo(torch.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating Points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# by default, python stores float data in fp64\n",
    "value = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.333333333333333314829616256247390992939472198486328125000000'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(value, '.60f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# 64-bit floating point\n",
    "tensor_fp64 = torch.tensor(value, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp64 tensor: 0.333333333333333314829616256247390992939472198486328125000000\n"
     ]
    }
   ],
   "source": [
    "print(f\"fp64 tensor: {format(tensor_fp64.item(), '.60f')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "tensor_fp32 = torch.tensor(value, dtype = torch.float32)\n",
    "tensor_fp16 = torch.tensor(value, dtype = torch.float16)\n",
    "tensor_bf16 = torch.tensor(value, dtype = torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp64 tensor: 0.333333333333333314829616256247390992939472198486328125000000\n",
      "fp32 tensor: 0.333333343267440795898437500000000000000000000000000000000000\n",
      "fp16 tensor: 0.333251953125000000000000000000000000000000000000000000000000\n",
      "bf16 tensor: 0.333984375000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "print(f\"fp64 tensor: {format(tensor_fp64.item(), '.60f')}\")\n",
    "print(f\"fp32 tensor: {format(tensor_fp32.item(), '.60f')}\")\n",
    "print(f\"fp16 tensor: {format(tensor_fp16.item(), '.60f')}\")\n",
    "print(f\"bf16 tensor: {format(tensor_bf16.item(), '.60f')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1699482682456,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 47,
    "id": "hUukczHrBodt",
    "outputId": "4e75bdf1-25b6-4e0c-9c08-18208e943b10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.01, min=-3.38953e+38, max=3.38953e+38, eps=0.0078125, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=bfloat16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information of `16-bit brain floating point`\n",
    "torch.finfo(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=1e-06, min=-3.40282e+38, max=3.40282e+38, eps=1.19209e-07, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information of `32-bit floating point`\n",
    "torch.finfo(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Information of `16-bit floating point`\n",
    "torch.finfo(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=1e-15, min=-1.79769e+308, max=1.79769e+308, eps=2.22045e-16, smallest_normal=2.22507e-308, tiny=2.22507e-308, dtype=float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Information of `64-bit floating point`\n",
    "torch.finfo(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DbtWVVc_jiW"
   },
   "source": [
    "### Downcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "height": 47,
    "id": "JHDsqfauBID9"
   },
   "outputs": [],
   "source": [
    "# random pytorch tensor: float32, size=1000\n",
    "tensor_fp32 = torch.rand(1000, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** As it is random, the values you get will be different from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1171, 0.0420, 0.2974, 0.4803, 0.9635])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 elements of the random tensor\n",
    "tensor_fp32[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "height": 47,
    "id": "xXLANbSx_nx4"
   },
   "outputs": [],
   "source": [
    "# downcast the tensor to bfloat16 using the \"to\" method\n",
    "tensor_fp32_to_bf16 = tensor_fp32.to(dtype = torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1172, 0.0420, 0.2969, 0.4805, 0.9648], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_fp32_to_bf16[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# tensor_fp32 x tensor_fp32\n",
    "m_float32 = torch.dot(tensor_fp32, tensor_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(333.8470)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# tensor_fp32_to_bf16 x tensor_fp32_to_bf16\n",
    "m_bfloat16 = torch.dot(tensor_fp32_to_bf16, tensor_fp32_to_bf16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(334., dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "- You'll use \"downcasting\" as a simple form of quantization in the next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKuOYgD21Zty8Z1Smilnjc",
   "collapsed_sections": [
    "x_9J8WavkQGl",
    "sulufN1wkK_L",
    "hqPUM0f8oGgf",
    "TgmPMm-ZvdXX",
    "MJuh8aqo9LO-",
    "3bOevU0Ez4KB",
    "LgtYIhSf0Uu0",
    "9DH7-tDDvK5N",
    "TuZhoPK6weuR",
    "WAOeSNraxZeF",
    "UGXo-IljxmNG",
    "_N3G-dX32awT",
    "hW7psx41rn0h",
    "OmcNPw6zlRp7",
    "3_zvORGrnTR8",
    "jh9IuiovrnoF",
    "isDcbkXxxiTf",
    "wM-xkASw1odi",
    "3DbtWVVc_jiW",
    "ViImpV5rAvyp",
    "RdcyknnjBD99",
    "-eYj4UUXCAlJ",
    "MCLe1N4GCSQT",
    "GIY7IrOv_3cD",
    "8HlFKDBKGNG8"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
