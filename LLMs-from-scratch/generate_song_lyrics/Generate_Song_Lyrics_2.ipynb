{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDbG4g8aSZez"
      },
      "source": [
        "# ðŸŽ¶ Song Lyrics Generation with GPT-2 and a GPT class\n",
        "\n",
        "This notebook fine-tunes a GPT-2 language model to generate original song lyrics in the style of specific artists (e.g., Blink-182, Weird Al Yankovic) using their actual lyrics as training data.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”§ What This Notebook Does\n",
        "\n",
        "1. **Preprocesses Lyrics**  \n",
        "   - Cleans and formats raw lyrics (removes headers, symbols, excess whitespace, etc.)\n",
        "\n",
        "2. **Fine-Tunes GPT-2**  \n",
        "   - Uses Hugging Face Transformers to fine-tune GPT-2 on cleaned lyrics  \n",
        "   - Training parameters like number of epochs and batch size are adjustable\n",
        "\n",
        "3. **Generates New Lyrics**  \n",
        "   - Prompts the model with a custom lyric or phrase  \n",
        "   - Outputs new lyrics in the trained artist's style  \n",
        "   - Optionally formats output into sections (e.g., `[Verse]`, `[Chorus]`)\n",
        "\n",
        "4. **Supports Multiple Artists**  \n",
        "   - Easily swap in different lyric datasets (e.g., Blink-182, Weird Al, etc.)  \n",
        "   - Modular structure for scraping, preprocessing, training, and generation\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“¦ Requirements\n",
        "\n",
        "- `transformers`  \n",
        "- `datasets`  \n",
        "- `torch`  \n",
        "\n",
        "---\n",
        "\n",
        "ðŸ’¡ It is not too difficult to generate songs from other artists.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by importing the necessary libraries."
      ],
      "metadata": {
        "id": "WLmh9vHnujk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "PNFV_LUUkSv7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import datasets\n",
        "from datasets import Dataset\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "GGL-xr2HOKZQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also log into Hugging Face."
      ],
      "metadata": {
        "id": "sUdo2TBvjPqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "7c89601e3b37448d9303ce52e98135aa",
            "7651f65c62864fb88eb8ddb8cc29b8c1",
            "e8aafb6aeb7a4f1096882504ba13aef0",
            "5a18fa9dc99a4ac8ad8319b4a193cfd0",
            "550e69568853423c9f047845ac90b5a0",
            "9b821fe2635744e1b3ea95c7e0576c21",
            "831c8e2828e5428ca25f3c556050857c",
            "d9900ed713c0444da992a570e4c3c6e0",
            "44993270eb244f8bb0897e23632fb27e",
            "19ef806a7d904e29a1786e08b073db19",
            "f3fc7768827a4e6e90d0809fd5f89a32",
            "84d302a6518d4dba8d6dbddbb7198bf4",
            "73789d9b4bc94744852755b5a276f2b4",
            "9820eec0a0014e73a3c20f25590f7b91",
            "991d327d572f483893b1ed5f2a34d609",
            "5104c7becb744e9ca9a59806db211df6",
            "da80f96ffd5e466d81cd886f6a1f92e9",
            "ef5322aca035455ba9db87a9576431a4",
            "63cb571ddb014b50a24b771e7c4c29e8",
            "e8bcd70323e1420eb839db62fd0e82d6"
          ]
        },
        "id": "MM4bB5ozjSDI",
        "outputId": "0fdbca0b-2d8b-435b-d7c2-0fbd74eedc90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c89601e3b37448d9303ce52e98135aa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then create a function to get lyrics through [lyrics.ovh](https://lyrics.ovh/)."
      ],
      "metadata": {
        "id": "Kteyv4kCilrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lyrics(artist, title):\n",
        "    \"\"\"\n",
        "    Fetch lyrics for a given song using the lyrics.ovh API.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    artist : str\n",
        "        The name of the artist (e.g., \"Weird Al Yankovic\").\n",
        "    title : str\n",
        "        The title of the song (e.g., \"Amish Paradise\").\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str or None\n",
        "        The song lyrics as a string if found; otherwise, None.\n",
        "    \"\"\"\n",
        "    # Construct the API URL with artist and title\n",
        "    url = f\"https://api.lyrics.ovh/v1/{artist}/{title}\"\n",
        "\n",
        "    # Make a GET request to the API\n",
        "    res = requests.get(url)\n",
        "\n",
        "    # If successful, extract lyrics from JSON\n",
        "    if res.status_code == 200:\n",
        "        lyrics = res.json().get(\"lyrics\", None)\n",
        "        return lyrics\n",
        "\n",
        "    # Return None if lyrics not found or request failed\n",
        "    return None"
      ],
      "metadata": {
        "id": "D97WnuSvikO2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blink 182 Song Generator"
      ],
      "metadata": {
        "id": "B0IfLYnaicSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our first example will generate songs from [Blink 182](https://en.wikipedia.org/wiki/Blink-182). We first provided a list of all known songs."
      ],
      "metadata": {
        "id": "TLaxyANpu6Rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blink_182_songs = [\n",
        "    \"All the Small Things\",\n",
        "    \"What's My Age Again?\",\n",
        "    \"I Miss You\",\n",
        "    \"Dammit\",\n",
        "    \"First Date\",\n",
        "    \"The Rock Show\",\n",
        "    \"Feeling This\",\n",
        "    \"Adam's Song\",\n",
        "    \"Stay Together for the Kids\",\n",
        "    \"Down\",\n",
        "    \"Man Overboard\",\n",
        "    \"Josie\",\n",
        "    \"Aliens Exist\",\n",
        "    \"Anthem Part Two\",\n",
        "    \"Reckless Abandon\",\n",
        "    \"Dumpweed\",\n",
        "    \"Not Now\",\n",
        "    \"Always\",\n",
        "    \"Bored to Death\",\n",
        "    \"Ghost on the Dance Floor\",\n",
        "    \"Up All Night\",\n",
        "    \"After Midnight\",\n",
        "    \"Darkside\",\n",
        "    \"Carousel\",\n",
        "    \"M+M's\",\n",
        "    \"Pathetic\",\n",
        "    \"Stockholm Syndrome\",\n",
        "    \"Violence\",\n",
        "    \"Asthenia\",\n",
        "    \"Go\",\n",
        "    \"Another Girl Another Planet\",\n",
        "    \"Natives\",\n",
        "    \"Wishing Well\",\n",
        "    \"Kaleidoscope\",\n",
        "    \"Hearts All Gone\",\n",
        "    \"Even If She Falls\",\n",
        "    \"She's Out of Her Mind\",\n",
        "    \"Los Angeles\",\n",
        "    \"Sober\",\n",
        "    \"Home Is Such a Lonely Place\",\n",
        "    \"Kings of the Weekend\",\n",
        "    \"Rabbit Hole\",\n",
        "    \"San Diego\",\n",
        "    \"Built This Pool\",\n",
        "    \"No Future\",\n",
        "    \"Teenage Satellites\",\n",
        "    \"Left Alone\",\n",
        "    \"Bottom of the Ocean\",\n",
        "    \"Long Lost Feeling\",\n",
        "    \"Wildfire\",\n",
        "    \"6/8\",\n",
        "    \"Parking Lot\",\n",
        "    \"Misery\",\n",
        "    \"Good Old Days\",\n",
        "    \"Don't Mean Anything\",\n",
        "    \"Hey I'm Sorry\",\n",
        "    \"Last Train Home\",\n",
        "    \"California\",\n",
        "    \"The Only Thing That Matters\",\n",
        "    \"Brohemian Rhapsody\",\n",
        "    \"Don't Leave Me\",\n",
        "    \"Happy Holidays, You Bastard\",\n",
        "    \"Story of a Lonely Guy\",\n",
        "    \"Give Me One Good Reason\",\n",
        "    \"Please Take Me Home\",\n",
        "    \"The Party Song\",\n",
        "    \"Online Songs\",\n",
        "    \"Shut Up\",\n",
        "    \"Roller Coaster\",\n",
        "    \"Time\",\n",
        "    \"Degenerate\",\n",
        "    \"Lemmings\",\n",
        "    \"Waggy\",\n",
        "    \"Enthused\",\n",
        "    \"Emo\",\n",
        "    \"Apple Shampoo\",\n",
        "    \"Untitled\",\n",
        "    \"Voyeur\",\n",
        "    \"I'm Sorry\",\n",
        "    \"Fentoozler\",\n",
        "    \"Romeo and Rebecca\",\n",
        "    \"Ben Wah Balls\",\n",
        "    \"Strings\",\n",
        "    \"Toast and Bananas\",\n",
        "    \"The Girl Next Door\",\n",
        "    \"Sometimes\",\n",
        "    \"TV\",\n",
        "    \"Depends\",\n",
        "    \"21 Days\",\n",
        "    \"Does My Breath Smell?\",\n",
        "    \"Cacophony\",\n",
        "    \"Zulu\",\n",
        "    \"Red Skies\",\n",
        "    \"Marlboro Man\",\n",
        "    \"The Family Next Door\",\n",
        "    \"Transvestite\",\n",
        "    \"Time to Break Up\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "KDnJp0J_iVqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then write the text and title of those songs into a text file."
      ],
      "metadata": {
        "id": "QFl09k4JvNaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = os.path.abspath(\"blink_182_lyrics.txt\")\n",
        "print(f\"Writing lyrics to: {output_path}\")\n",
        "\n",
        "with open(\"blink_182_lyrics.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for title in blink_182_songs:\n",
        "        print(f\"Fetching: {title}\")\n",
        "        lyrics = get_lyrics(\"Blink 182\", title)\n",
        "\n",
        "        if lyrics:\n",
        "            f.write(f\"### {title} ###\\n{lyrics}\\n\\n\")\n",
        "            print(f\"âœ… Wrote: {title}\")\n",
        "        else:\n",
        "            f.write(f\"### {title} ###\\nLyrics not found.\\n\\n\")\n",
        "            print(f\"âŒ Not found: {title}\")\n",
        "        time.sleep(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s3LIqvpcIEt",
        "outputId": "17637921-959c-4e0c-da9d-a6ef022d1c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lyrics to: /content/blink_182_lyrics.txt\n",
            "Fetching: All the Small Things\n",
            "âœ… Wrote: All the Small Things\n",
            "Fetching: What's My Age Again?\n",
            "âœ… Wrote: What's My Age Again?\n",
            "Fetching: I Miss You\n",
            "âœ… Wrote: I Miss You\n",
            "Fetching: Dammit\n",
            "âœ… Wrote: Dammit\n",
            "Fetching: First Date\n",
            "âœ… Wrote: First Date\n",
            "Fetching: The Rock Show\n",
            "âœ… Wrote: The Rock Show\n",
            "Fetching: Feeling This\n",
            "âœ… Wrote: Feeling This\n",
            "Fetching: Adam's Song\n",
            "âœ… Wrote: Adam's Song\n",
            "Fetching: Stay Together for the Kids\n",
            "âœ… Wrote: Stay Together for the Kids\n",
            "Fetching: Down\n",
            "âœ… Wrote: Down\n",
            "Fetching: Man Overboard\n",
            "âœ… Wrote: Man Overboard\n",
            "Fetching: Josie\n",
            "âœ… Wrote: Josie\n",
            "Fetching: Aliens Exist\n",
            "âœ… Wrote: Aliens Exist\n",
            "Fetching: Anthem Part Two\n",
            "âŒ Not found: Anthem Part Two\n",
            "Fetching: Reckless Abandon\n",
            "âœ… Wrote: Reckless Abandon\n",
            "Fetching: Dumpweed\n",
            "âœ… Wrote: Dumpweed\n",
            "Fetching: Not Now\n",
            "âœ… Wrote: Not Now\n",
            "Fetching: Always\n",
            "âœ… Wrote: Always\n",
            "Fetching: Bored to Death\n",
            "âœ… Wrote: Bored to Death\n",
            "Fetching: Ghost on the Dance Floor\n",
            "âœ… Wrote: Ghost on the Dance Floor\n",
            "Fetching: Up All Night\n",
            "âœ… Wrote: Up All Night\n",
            "Fetching: After Midnight\n",
            "âŒ Not found: After Midnight\n",
            "Fetching: Darkside\n",
            "âœ… Wrote: Darkside\n",
            "Fetching: Carousel\n",
            "âœ… Wrote: Carousel\n",
            "Fetching: M+M's\n",
            "âŒ Not found: M+M's\n",
            "Fetching: Pathetic\n",
            "âœ… Wrote: Pathetic\n",
            "Fetching: Stockholm Syndrome\n",
            "âœ… Wrote: Stockholm Syndrome\n",
            "Fetching: Violence\n",
            "âœ… Wrote: Violence\n",
            "Fetching: Asthenia\n",
            "âœ… Wrote: Asthenia\n",
            "Fetching: Go\n",
            "âœ… Wrote: Go\n",
            "Fetching: Another Girl Another Planet\n",
            "âœ… Wrote: Another Girl Another Planet\n",
            "Fetching: Natives\n",
            "âœ… Wrote: Natives\n",
            "Fetching: Wishing Well\n",
            "âœ… Wrote: Wishing Well\n",
            "Fetching: Kaleidoscope\n",
            "âœ… Wrote: Kaleidoscope\n",
            "Fetching: Hearts All Gone\n",
            "âœ… Wrote: Hearts All Gone\n",
            "Fetching: Even If She Falls\n",
            "âœ… Wrote: Even If She Falls\n",
            "Fetching: She's Out of Her Mind\n",
            "âœ… Wrote: She's Out of Her Mind\n",
            "Fetching: Los Angeles\n",
            "âœ… Wrote: Los Angeles\n",
            "Fetching: Sober\n",
            "âœ… Wrote: Sober\n",
            "Fetching: Home Is Such a Lonely Place\n",
            "âœ… Wrote: Home Is Such a Lonely Place\n",
            "Fetching: Kings of the Weekend\n",
            "âœ… Wrote: Kings of the Weekend\n",
            "Fetching: Rabbit Hole\n",
            "âœ… Wrote: Rabbit Hole\n",
            "Fetching: San Diego\n",
            "âœ… Wrote: San Diego\n",
            "Fetching: Built This Pool\n",
            "âœ… Wrote: Built This Pool\n",
            "Fetching: No Future\n",
            "âœ… Wrote: No Future\n",
            "Fetching: Teenage Satellites\n",
            "âœ… Wrote: Teenage Satellites\n",
            "Fetching: Left Alone\n",
            "âœ… Wrote: Left Alone\n",
            "Fetching: Bottom of the Ocean\n",
            "âœ… Wrote: Bottom of the Ocean\n",
            "Fetching: Long Lost Feeling\n",
            "âœ… Wrote: Long Lost Feeling\n",
            "Fetching: Wildfire\n",
            "âœ… Wrote: Wildfire\n",
            "Fetching: 6/8\n",
            "âŒ Not found: 6/8\n",
            "Fetching: Parking Lot\n",
            "âœ… Wrote: Parking Lot\n",
            "Fetching: Misery\n",
            "âœ… Wrote: Misery\n",
            "Fetching: Good Old Days\n",
            "âœ… Wrote: Good Old Days\n",
            "Fetching: Don't Mean Anything\n",
            "âœ… Wrote: Don't Mean Anything\n",
            "Fetching: Hey I'm Sorry\n",
            "âœ… Wrote: Hey I'm Sorry\n",
            "Fetching: Last Train Home\n",
            "âœ… Wrote: Last Train Home\n",
            "Fetching: California\n",
            "âœ… Wrote: California\n",
            "Fetching: The Only Thing That Matters\n",
            "âœ… Wrote: The Only Thing That Matters\n",
            "Fetching: Brohemian Rhapsody\n",
            "âœ… Wrote: Brohemian Rhapsody\n",
            "Fetching: Don't Leave Me\n",
            "âœ… Wrote: Don't Leave Me\n",
            "Fetching: Happy Holidays, You Bastard\n",
            "âœ… Wrote: Happy Holidays, You Bastard\n",
            "Fetching: Story of a Lonely Guy\n",
            "âœ… Wrote: Story of a Lonely Guy\n",
            "Fetching: Give Me One Good Reason\n",
            "âœ… Wrote: Give Me One Good Reason\n",
            "Fetching: Please Take Me Home\n",
            "âœ… Wrote: Please Take Me Home\n",
            "Fetching: The Party Song\n",
            "âœ… Wrote: The Party Song\n",
            "Fetching: Online Songs\n",
            "âœ… Wrote: Online Songs\n",
            "Fetching: Shut Up\n",
            "âœ… Wrote: Shut Up\n",
            "Fetching: Roller Coaster\n",
            "âœ… Wrote: Roller Coaster\n",
            "Fetching: Time\n",
            "âœ… Wrote: Time\n",
            "Fetching: Degenerate\n",
            "âœ… Wrote: Degenerate\n",
            "Fetching: Lemmings\n",
            "âŒ Not found: Lemmings\n",
            "Fetching: Waggy\n",
            "âœ… Wrote: Waggy\n",
            "Fetching: Enthused\n",
            "âœ… Wrote: Enthused\n",
            "Fetching: Emo\n",
            "âŒ Not found: Emo\n",
            "Fetching: Apple Shampoo\n",
            "âŒ Not found: Apple Shampoo\n",
            "Fetching: Untitled\n",
            "âœ… Wrote: Untitled\n",
            "Fetching: Voyeur\n",
            "âœ… Wrote: Voyeur\n",
            "Fetching: I'm Sorry\n",
            "âœ… Wrote: I'm Sorry\n",
            "Fetching: Fentoozler\n",
            "âœ… Wrote: Fentoozler\n",
            "Fetching: Romeo and Rebecca\n",
            "âœ… Wrote: Romeo and Rebecca\n",
            "Fetching: Ben Wah Balls\n",
            "âœ… Wrote: Ben Wah Balls\n",
            "Fetching: Strings\n",
            "âœ… Wrote: Strings\n",
            "Fetching: Toast and Bananas\n",
            "âœ… Wrote: Toast and Bananas\n",
            "Fetching: The Girl Next Door\n",
            "âœ… Wrote: The Girl Next Door\n",
            "Fetching: Sometimes\n",
            "âœ… Wrote: Sometimes\n",
            "Fetching: TV\n",
            "âœ… Wrote: TV\n",
            "Fetching: Depends\n",
            "âœ… Wrote: Depends\n",
            "Fetching: 21 Days\n",
            "âœ… Wrote: 21 Days\n",
            "Fetching: Does My Breath Smell?\n",
            "âœ… Wrote: Does My Breath Smell?\n",
            "Fetching: Cacophony\n",
            "âœ… Wrote: Cacophony\n",
            "Fetching: Zulu\n",
            "âœ… Wrote: Zulu\n",
            "Fetching: Red Skies\n",
            "âœ… Wrote: Red Skies\n",
            "Fetching: Marlboro Man\n",
            "âŒ Not found: Marlboro Man\n",
            "Fetching: The Family Next Door\n",
            "âœ… Wrote: The Family Next Door\n",
            "Fetching: Transvestite\n",
            "âœ… Wrote: Transvestite\n",
            "Fetching: Time to Break Up\n",
            "âœ… Wrote: Time to Break Up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we preprocessed the raw lyrics and use the Hugging Face transformers library to fine-tune GPT-2."
      ],
      "metadata": {
        "id": "1M68XOn4jxtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_lyrics(lyrics):\n",
        "    \"\"\"\n",
        "    Clean and normalize song lyrics for training.\n",
        "\n",
        "    This function removes section headers (e.g., [Chorus]),\n",
        "    extra newlines, and punctuation (except apostrophes),\n",
        "    and converts all text to lowercase.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lyrics : str\n",
        "        The raw lyrics text to preprocess.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        A cleaned, normalized string of lyrics.\n",
        "    \"\"\"\n",
        "    lyrics = re.sub(r'\\[.*?\\]', '', lyrics)  # Remove [Verse], [Chorus], etc.\n",
        "    lyrics = re.sub(r'\\n{2,}', '\\n', lyrics)  # Replace multiple newlines with a single newline\n",
        "    lyrics = re.sub(r'[^\\w\\s\\']', '', lyrics)  # Remove punctuation except apostrophes\n",
        "    lyrics = lyrics.lower()  # Convert all text to lowercase\n",
        "    return lyrics\n",
        "\n",
        "\n",
        "def fine_tune_gpt2(lyrics_text, output_dir):\n",
        "    \"\"\"\n",
        "    Fine-tune a GPT-2 language model on provided song lyrics.\n",
        "\n",
        "    This function tokenizes the input lyrics, creates a dataset,\n",
        "    and uses Hugging Face's Trainer API to fine-tune a GPT-2 model.\n",
        "    The model and tokenizer are saved to the specified output directory.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lyrics_text : str\n",
        "        The preprocessed lyrics text used for training.\n",
        "\n",
        "    output_dir : str\n",
        "        Path to the directory where the fine-tuned model will be saved.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Load GPT-2 tokenizer and set pad token\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Split lyrics into chunks (each chunk is a training sample)\n",
        "    chunks = lyrics_text.strip().split(\"\\n\")\n",
        "    chunks = [c.strip() for c in chunks if len(c.strip()) > 20]\n",
        "\n",
        "    # Tokenize the text chunks into input tensors\n",
        "    encodings = tokenizer(chunks, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    # Convert encodings to Hugging Face Dataset\n",
        "    dataset = Dataset.from_dict({\n",
        "        \"input_ids\": encodings[\"input_ids\"],\n",
        "        \"attention_mask\": encodings[\"attention_mask\"]\n",
        "    })\n",
        "\n",
        "    # Load base GPT-2 model\n",
        "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "    # Setup data collator for causal language modeling (no masking)\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False  # Masked LM is for BERT-like models; GPT uses causal LM\n",
        "    )\n",
        "\n",
        "    # Define training configuration\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=10,\n",
        "        per_device_train_batch_size=4,\n",
        "        save_steps=500,\n",
        "        save_total_limit=2,\n",
        "        logging_dir=\"./logs\",\n",
        "        logging_steps=100,\n",
        "        report_to=\"none\"  # Disable default logging to Weights and Biases or TensorBoard\n",
        "    )\n",
        "\n",
        "    # Initialize Hugging Face Trainer for model training\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset,\n",
        "        data_collator=data_collator\n",
        "    )\n",
        "\n",
        "    # Run training\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the fine-tuned model to the output directory\n",
        "    trainer.save_model(output_dir)\n",
        "    print(f\"âœ… Model saved to: {output_dir}\")"
      ],
      "metadata": {
        "id": "4H6rfpSyjzII"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The commands below fine tune the GPT-2 model on the preprocessed text."
      ],
      "metadata": {
        "id": "htgkLkKhvfJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the file content\n",
        "with open(\"blink_182_lyrics.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    blink_lyrics_raw = f.read()\n",
        "\n",
        "# Preprocess the text\n",
        "blink_lyrics_clean = preprocess_lyrics(blink_lyrics_raw)\n",
        "\n",
        "# Fine-tune GPT-2\n",
        "fine_tune_gpt2(blink_lyrics_clean, \"blink_gpt2_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5479e124f5d54fcca35eda5ead3ad565",
            "d0af8a04ba85410fafa8977c155d2099",
            "0cf652af0eb44def9de04bd3c135bf2b",
            "7d56fb8a02f1498d9987b5cf9082249b",
            "bcecc9c8b44f482c8c3e01b02d29f636",
            "caa13203146d483fbe93f61e1b91b611",
            "d04a5ce4f9f543dcb40fe2dc7e2d7b7e",
            "3c1382297b054ee68e1f289d1af41aa7",
            "bdcb28cc549f4af49805695dcebb00c9",
            "3db81457b9334036a371b930cff2a1a3",
            "80ce7f4eb3794d0fae591f02dc8ec34f",
            "3f6d854b8fa1490aadbb8d5eb5776504",
            "0bcc57393c5e4391bfa075f6df83d54e",
            "2bcf3d13234d4fa0be4279ac487d871c",
            "d57952ab796d40c084a7a640e2fee268",
            "3497229640b84840bd2b44ba44676a2b",
            "9d8ccb02fb804257a9843109218846da",
            "3f45e8f8f7564610822abb1b455cc92e",
            "5a8e0671bc3849b1be2bece25dd6b9d3",
            "4287abb80d9248dbbff29f07d7aa497a",
            "599f5061c6ea4ff6b7c1b7fbf5586fc5",
            "ccf9aac32ec54a939852b08d4bd24947"
          ]
        },
        "id": "BfvZd6aXl4wI",
        "outputId": "f88bd6f5-4fd5-4950-cb55-6e2901e77e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5479e124f5d54fcca35eda5ead3ad565"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f6d854b8fa1490aadbb8d5eb5776504"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6090' max='6090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6090/6090 20:48, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.894500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.653400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.422700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.368300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.188300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.102800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>2.530300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>2.393700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>2.246500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.344600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>2.336900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>2.181000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.911400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.692700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.783500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.623200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.627500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>1.457000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.344800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.257400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>1.352500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>1.323700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>1.347700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.133500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>1.055900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>1.107100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>1.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>1.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.044800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.980100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.890500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.859500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.899400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.914200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.986700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.863700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.811400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.797500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.838800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.818200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.813500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.757500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.711000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.726900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.729300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.769800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.765700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.729000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.690500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.715400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.695300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.699500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.685400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.673700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.639700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.640500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.679500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.648700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.654300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved to: blink_gpt2_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then create multiple helper functions in an attempt to mimic the style of Blink 182."
      ],
      "metadata": {
        "id": "p2FxYIqlvvYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_into_lyric_lines(text):\n",
        "    \"\"\"\n",
        "    Split raw generated text into structured lyric lines.\n",
        "\n",
        "    This function uses sentence-ending punctuation to break the text into\n",
        "    lines. If a sentence is too long, it is further split into smaller\n",
        "    chunks of about 10 words each.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "        Raw text output from the language model.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list of str\n",
        "        A list of cleaned and trimmed lyric lines.\n",
        "    \"\"\"\n",
        "    # Split text on sentence boundaries (periods, question marks, exclamations)\n",
        "    lines = re.split(r'(?<=[.!?])\\s+', text)\n",
        "    result = []\n",
        "\n",
        "    # Further chunk long lines into smaller pieces\n",
        "    for line in lines:\n",
        "        if len(line.split()) > 14:\n",
        "            chunks = line.split()\n",
        "            for i in range(0, len(chunks), 10):\n",
        "                result.append(\" \".join(chunks[i:i+10]))\n",
        "        else:\n",
        "            result.append(line.strip())\n",
        "\n",
        "    # Return non-empty lines, trimmed of whitespace\n",
        "    return [l.strip() for l in result if l.strip()]\n",
        "\n",
        "\n",
        "def clean_lyrics_lines(lines):\n",
        "    \"\"\"\n",
        "    Remove any duplicated section headers from the list of lyrics.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lines : list of str\n",
        "        List of lyric lines possibly containing section headers like [Verse].\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list of str\n",
        "        Cleaned lines without section header duplicates.\n",
        "    \"\"\"\n",
        "    return [line for line in lines if not re.match(r'\\[.*?\\]', line.strip())]\n",
        "\n",
        "\n",
        "def format_as_blink_song(raw_text, lines_per_block=(4, 6)):\n",
        "    \"\"\"\n",
        "    Format raw text into a Blink-182 style song with section headers.\n",
        "\n",
        "    The song is divided into typical Blink-style sections like Verse,\n",
        "    Chorus, Bridge, and Outro, using a set number of lines per section.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    raw_text : str\n",
        "        Raw generated lyrics text from the language model.\n",
        "    lines_per_block : tuple of int, optional\n",
        "        Range (min, max) for how many lines appear in each section.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Formatted song text with section headers and lyric lines.\n",
        "    \"\"\"\n",
        "    lines = split_into_lyric_lines(raw_text)\n",
        "    lines = clean_lyrics_lines(lines)\n",
        "\n",
        "    # Define a typical Blink-182 song structure\n",
        "    section_template = [\"[Verse 1]\", \"[Chorus]\", \"[Verse 2]\", \"[Chorus]\", \"[Bridge]\", \"[Chorus]\", \"[Outro]\"]\n",
        "    output = []\n",
        "\n",
        "    i = 0\n",
        "    for section in section_template:\n",
        "        block_size = random.randint(*lines_per_block)\n",
        "        block_lines = lines[i:i+block_size]\n",
        "\n",
        "        if not block_lines:\n",
        "            break\n",
        "\n",
        "        output.append(section)\n",
        "        output.extend(block_lines)\n",
        "        output.append(\"\")  # Add empty line between sections\n",
        "        i += block_size\n",
        "\n",
        "    return \"\\n\".join(output)\n",
        "\n",
        "\n",
        "def trim_repetition(text, word=\"yeah\", limit=8):\n",
        "    \"\"\"\n",
        "    Trim long sequences of repeating words in generated text.\n",
        "\n",
        "    This helps prevent runaway loops like 'yeah yeah yeah yeah...'.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "        The raw generated lyrics text.\n",
        "    word : str\n",
        "        The word to limit repetitions of.\n",
        "    limit : int\n",
        "        Maximum number of allowed repeated instances.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        The cleaned text with repeated words trimmed.\n",
        "    \"\"\"\n",
        "    pattern = r\"\\b(\" + word + r\"\\s*){\" + str(limit) + r\",}\"\n",
        "    return re.sub(pattern, f\"{word} \" * 2, text, flags=re.IGNORECASE)\n",
        "\n",
        "\n",
        "def generate_blink_song(prompt=\"i never thought that this would hurt\", model_dir=\"blink_gpt2_model\",\n",
        "                        output_file=\"generated_blink_song.txt\", max_length=300, temperature=0.9):\n",
        "    \"\"\"\n",
        "    Generate a Blink-182 style song from a GPT-2 model.\n",
        "\n",
        "    This function uses a fine-tuned GPT-2 model to generate lyrics based on a given\n",
        "    prompt. It formats the output into a structured pop-punk song and saves it to a file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    prompt : str, optional\n",
        "        Initial seed text to start the song.\n",
        "    model_dir : str\n",
        "        Directory where the fine-tuned model is stored.\n",
        "    output_file : str\n",
        "        File path to save the generated lyrics.\n",
        "    max_length : int, optional\n",
        "        Maximum token length for the generated output.\n",
        "    temperature : float, optional\n",
        "        Sampling temperature for creativity. Higher = more random.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Load model and tokenizer from the specified directory\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_dir)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
        "    model.eval()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model.to(\"cuda\")\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        input_ids = input_ids.to(\"cuda\")\n",
        "        attention_mask = attention_mask.to(\"cuda\")\n",
        "\n",
        "    # Generate text from the model\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=temperature,\n",
        "            repetition_penalty=1.2,\n",
        "            num_return_sequences=1,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode and post-process the output\n",
        "    raw_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    clean_text = trim_repetition(raw_text)\n",
        "    formatted_song = format_as_blink_song(clean_text)\n",
        "\n",
        "    # Save to file\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(formatted_song)\n",
        "\n",
        "    print(f\"âœ… Blink-182-style song saved to '{output_file}'\\n\")\n",
        "    print(\"ðŸŽ¤ The song:\\n\")\n",
        "    print(formatted_song)"
      ],
      "metadata": {
        "id": "hMh2-KT7n4B1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then generate two Blink 182 songs."
      ],
      "metadata": {
        "id": "JHPxMsw3xi5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_blink_song(\n",
        "    prompt=\"I spoke with my best friend about my new song\",\n",
        "    model_dir=\"blink_gpt2_model\",\n",
        "    output_file=\"my_blink_song.txt\",\n",
        "    max_length=500,\n",
        "    temperature=0.8\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVmO5BrundgU",
        "outputId": "ce84b665-8721-430f-d005-2244a6ba61e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Blink-182-style song saved to 'my_blink_song.txt'\n",
            "\n",
            "ðŸŽ¤ The song:\n",
            "\n",
            "[Verse 1]\n",
            "I spoke with my best friend about my new song\n",
            "'cause it's called Young Thug and he just doesn't listen\n",
            "to me anymore cause i hate his music now and\n",
            "then i saw the lyrics on his album cover ooh\n",
            "oh yeah thats what happened when we fell in love\n",
            "but that shit never ends even if she falls in\n",
            "\n",
            "[Chorus]\n",
            "love you still keep hating me forever and afterand its\n",
            "over there is nothing left for me to grow up\n",
            "about it no future at all i donhope this won\n",
            "change your heart only thing will be rightthis hurts like\n",
            "hell every time i start crying why can people ignore\n",
            "me because of my mistakes did you hear those words\n",
            "\n",
            "[Verse 2]\n",
            "spoken by everyone around me how could you not understand\n",
            "id rather act different so instead i'm a jerk i'm\n",
            "a punk rock star everything has gone wrong always trying\n",
            "hard enough to impress girls who look down on me\n",
            "\n",
            "[Chorus]\n",
            "they try too hard to please me as well im\n",
            "getting older than anyone else their brain is starting to\n",
            "atrocious teenage hormones make me crazy often times until finally\n",
            "one day i find something better to call you name\n",
            "why would need to fight another day of work less\n",
            "needed to grow up believing me x2 now fading fast\n",
            "\n",
            "[Bridge]\n",
            "life comes back to haunt me 4 more years of\n",
            "failing then ever since our last night together 23 months\n",
            "i've been apart feeling these things are growing up inside\n",
            "me worse each week worse than before 7 times a\n",
            "day when we're together again two days later and almost\n",
            "\n",
            "[Chorus]\n",
            "forgotten alive walking backwards through the front door barely standing\n",
            "next turn twice daily check out the panty hose and\n",
            "let the engine die away replaced my breathe it kills\n",
            "me everyday while breathing deeply living without oxygen rarely leave\n",
            "me here haunting me for awhile now wasting hours staring\n",
            "\n",
            "[Outro]\n",
            "at the ceiling trying to figure out where am i\n",
            "supposed to go home now hating everything about you and\n",
            "loving you till its done rightit feels good calling you\n",
            "names and ending up dead or dying alone underneath the\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_blink_song(\n",
        "    prompt=\"I like to hang out with my friends\",\n",
        "    model_dir=\"blink_gpt2_model\",\n",
        "    output_file=\"my_blink_song_2.txt\",\n",
        "    max_length=500,\n",
        "    temperature=0.4\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5raglGR1sl0",
        "outputId": "eecd582f-08c3-4c60-bc37-eb470ddf1c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Blink-182-style song saved to 'my_blink_song_2.txt'\n",
            "\n",
            "ðŸŽ¤ The song:\n",
            "\n",
            "[Verse 1]\n",
            "I like to hang out with my friends who are\n",
            "more prodigal than me so i could have some fun\n",
            "at the risk of sounding rude towards you if you'd\n",
            "tell me what you wanted to know about me i\n",
            "\n",
            "[Chorus]\n",
            "guess you best be on your way home from school\n",
            "anyway cause that's where i grew up and now im\n",
            "living life is better then it was when i was\n",
            "in a bar fight maybe its just another night alone\n",
            "for sure but thats all id ever hoped for oh\n",
            "\n",
            "[Verse 2]\n",
            "yeah well ill meet these guys once again why can't\n",
            "we go date night let's make this last forever rather\n",
            "than waste time together how did we get here teenage\n",
            "haze tonight got caught urinating on his pants they dragged\n",
            "him down to the edge of townshe said dont listen\n",
            "\n",
            "[Chorus]\n",
            "to me son i'm not listening to you no future\n",
            "there will be no future there won every time i\n",
            "grow up feeling scared of what you think of me\n",
            "oh wait until i'm older then i'm too scared to\n",
            "\n",
            "[Bridge]\n",
            "move cause today's the day before tomorrow's the week that\n",
            "matters most to me nothing more to me than getting\n",
            "laid yeah look into my mind california has got so\n",
            "much more to do WITHLESS TIME WILLIE x2 give me\n",
            "\n",
            "[Chorus]\n",
            "one hell yeah i'll live without it's just so damn\n",
            "hard to fall back inside my head i've always thought\n",
            "that everything was gonna BE fineuntil its too late come\n",
            "to tryURE meaning after all those years of struggle everything\n",
            "\n",
            "[Outro]\n",
            "will finally be rightohhope god invented chicago has such a\n",
            "city now its called 'the valley' cause people call it\n",
            "what it means less love and hateand worse lies wont\n",
            "work as truth hurts feelings hurt each other so bad\n",
            "things wont happen to us even if we stay the\n",
            "same hating them both so good reason to leave our\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weird Al Song Generator"
      ],
      "metadata": {
        "id": "_2hdJzQFytL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now analyze songs from [Weird Al](https://en.wikipedia.org/wiki/%22Weird_Al%22_Yankovic)."
      ],
      "metadata": {
        "id": "N46E_olU3gTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weird_al_songs = [\n",
        "    \"Achy Breaky Song\",\n",
        "    \"Airline Amy\",\n",
        "    \"Albuquerque\",\n",
        "    \"All About the Pentiums\",\n",
        "    \"Amish Paradise\",\n",
        "    \"Another One Rides the Bus\",\n",
        "    \"Attack of the Radioactive Hamsters from a Planet near Mars\",\n",
        "    \"Bedrock Anthem\",\n",
        "    \"Biggest Ball of Twine in Minnesota\",\n",
        "    \"Bob\",\n",
        "    \"Bohemian Polka\",\n",
        "    \"Buckingham Blues\",\n",
        "    \"Callin' in Sick\",\n",
        "    \"Canadian Idiot\",\n",
        "    \"Cavity Search\",\n",
        "    \"Christmas at Ground Zero\",\n",
        "    \"Close but No Cigar\",\n",
        "    \"CNR\",\n",
        "    \"Craigslist\",\n",
        "    \"Dare to Be Stupid\",\n",
        "    \"Don't Download This Song\",\n",
        "    \"Do I Creep You Out\",\n",
        "    \"Eat It\",\n",
        "    \"eBay\",\n",
        "    \"Everything You Know Is Wrong\",\n",
        "    \"Fat\",\n",
        "    \"First World Problems\",\n",
        "    \"Foil\",\n",
        "    \"Frank's 2000' TV\",\n",
        "    \"Genius in France\",\n",
        "    \"Germs\",\n",
        "    \"Good Enough for Now\",\n",
        "    \"Grapefruit Diet\",\n",
        "    \"Gump\",\n",
        "    \"Handy\",\n",
        "    \"Hardware Store\",\n",
        "    \"Headline News\",\n",
        "    \"I Can't Watch This\",\n",
        "    \"I Love Rocky Road\",\n",
        "    \"I Lost on Jeopardy\",\n",
        "    \"I Remember Larry\",\n",
        "    \"I Think I'm a Clone Now\",\n",
        "    \"I Want a New Duck\",\n",
        "    \"I'll Sue Ya\",\n",
        "    \"If That Isn't Love\",\n",
        "    \"Inactive\",\n",
        "    \"It's All About the Pentiums\",\n",
        "    \"Jackson Park Express\",\n",
        "    \"Jerry Springer\",\n",
        "    \"Jurassic Park\",\n",
        "    \"King of Suede\",\n",
        "    \"Lasagna\",\n",
        "    \"Let Me Be Your Hog\",\n",
        "    \"Like a Surgeon\",\n",
        "    \"Livin' in the Fridge\",\n",
        "    \"Living with a Hernia\",\n",
        "    \"Midnight Star\",\n",
        "    \"Money for Nothing/Beverly Hillbillies*\",\n",
        "    \"Mr. Frump in the Iron Lung\",\n",
        "    \"My Baby's in Love with Eddie Vedder\",\n",
        "    \"My Bologna\",\n",
        "    \"My Own Eyes\",\n",
        "    \"Nature Trail to Hell\",\n",
        "    \"One More Minute\",\n",
        "    \"Pancreas\",\n",
        "    \"Party at the Leper Colony\",\n",
        "    \"Party in the CIA\",\n",
        "    \"Perform This Way\",\n",
        "    \"Polka Face\",\n",
        "    \"Polka Your Eyes Out\",\n",
        "    \"Polkas on 45\",\n",
        "    \"Pretty Fly for a Rabbi\",\n",
        "    \"Ricky\",\n",
        "    \"She Drives Like Crazy\",\n",
        "    \"Skipper Dan\",\n",
        "    \"Smells Like Nirvana\",\n",
        "    \"Spam\",\n",
        "    \"Sports Song\",\n",
        "    \"Stop Forwarding That Crap to Me\",\n",
        "    \"Stuck in a Closet with Vanna White\",\n",
        "    \"Such a Groovy Guy\",\n",
        "    \"Taco Grande\",\n",
        "    \"Tacky\",\n",
        "    \"Talk Soup\",\n",
        "    \"The Alternative Polka\",\n",
        "    \"The Biggest Ball of Twine in Minnesota\",\n",
        "    \"The Check's in the Mail\",\n",
        "    \"The Hamilton Polka\",\n",
        "    \"The Night Santa Went Crazy\",\n",
        "    \"The Plumbing Song\",\n",
        "    \"The Saga Begins\",\n",
        "    \"The White Stuff\",\n",
        "    \"This Is the Life\",\n",
        "    \"Traffic Jam\",\n",
        "    \"Trapped in the Drive-Thru\",\n",
        "    \"Trigger Happy\",\n",
        "    \"Twister\",\n",
        "    \"UHF\",\n",
        "    \"Velvet Elvis\",\n",
        "    \"Virus Alert\",\n",
        "    \"Wanna B Ur Lovr\",\n",
        "    \"Weasel Stomping Day\",\n",
        "    \"Whatever You Like\",\n",
        "    \"When I Was Your Age\",\n",
        "    \"White & Nerdy\",\n",
        "    \"Why Does This Always Happen to Me?\",\n",
        "    \"Word Crimes\",\n",
        "    \"You Don't Love Me Anymore\",\n",
        "    \"Young, Dumb & Ugly\",\n",
        "    \"Your Horoscope for Today\",\n",
        "    \"Yoda\"\n",
        "]"
      ],
      "metadata": {
        "id": "L2f9EKAd3i_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also write the text and title of those songs into a text file."
      ],
      "metadata": {
        "id": "7evn912t3zAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = os.path.abspath(\"weird_al_lyrics.txt\")\n",
        "print(f\"Writing lyrics to: {output_path}\")\n",
        "\n",
        "with open(\"weird_al_lyrics.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for title in weird_al_songs:\n",
        "        print(f\"Fetching: {title}\")\n",
        "        lyrics = get_lyrics(\"Weird Al Yankovic\", title)\n",
        "\n",
        "        if lyrics:\n",
        "            f.write(f\"### {title} ###\\n{lyrics}\\n\\n\")\n",
        "            print(f\"âœ… Wrote: {title}\")\n",
        "        else:\n",
        "            f.write(f\"### {title} ###\\nLyrics not found.\\n\\n\")\n",
        "            print(f\"âŒ Not found: {title}\")\n",
        "        time.sleep(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjSewnRc31qN",
        "outputId": "c1c04d26-b3fc-4fd9-e202-bc02ff00e561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lyrics to: /content/weird_al_lyrics.txt\n",
            "Fetching: Achy Breaky Song\n",
            "âœ… Wrote: Achy Breaky Song\n",
            "Fetching: Airline Amy\n",
            "âœ… Wrote: Airline Amy\n",
            "Fetching: Albuquerque\n",
            "âœ… Wrote: Albuquerque\n",
            "Fetching: All About the Pentiums\n",
            "âŒ Not found: All About the Pentiums\n",
            "Fetching: Amish Paradise\n",
            "âœ… Wrote: Amish Paradise\n",
            "Fetching: Another One Rides the Bus\n",
            "âœ… Wrote: Another One Rides the Bus\n",
            "Fetching: Attack of the Radioactive Hamsters from a Planet near Mars\n",
            "âœ… Wrote: Attack of the Radioactive Hamsters from a Planet near Mars\n",
            "Fetching: Bedrock Anthem\n",
            "âŒ Not found: Bedrock Anthem\n",
            "Fetching: Biggest Ball of Twine in Minnesota\n",
            "âŒ Not found: Biggest Ball of Twine in Minnesota\n",
            "Fetching: Bob\n",
            "âœ… Wrote: Bob\n",
            "Fetching: Bohemian Polka\n",
            "âŒ Not found: Bohemian Polka\n",
            "Fetching: Buckingham Blues\n",
            "âœ… Wrote: Buckingham Blues\n",
            "Fetching: Callin' in Sick\n",
            "âŒ Not found: Callin' in Sick\n",
            "Fetching: Canadian Idiot\n",
            "âœ… Wrote: Canadian Idiot\n",
            "Fetching: Cavity Search\n",
            "âŒ Not found: Cavity Search\n",
            "Fetching: Christmas at Ground Zero\n",
            "âœ… Wrote: Christmas at Ground Zero\n",
            "Fetching: Close but No Cigar\n",
            "âœ… Wrote: Close but No Cigar\n",
            "Fetching: CNR\n",
            "âœ… Wrote: CNR\n",
            "Fetching: Craigslist\n",
            "âœ… Wrote: Craigslist\n",
            "Fetching: Dare to Be Stupid\n",
            "âœ… Wrote: Dare to Be Stupid\n",
            "Fetching: Don't Download This Song\n",
            "âœ… Wrote: Don't Download This Song\n",
            "Fetching: Do I Creep You Out\n",
            "âœ… Wrote: Do I Creep You Out\n",
            "Fetching: Eat It\n",
            "âœ… Wrote: Eat It\n",
            "Fetching: eBay\n",
            "âœ… Wrote: eBay\n",
            "Fetching: Everything You Know Is Wrong\n",
            "âŒ Not found: Everything You Know Is Wrong\n",
            "Fetching: Fat\n",
            "âœ… Wrote: Fat\n",
            "Fetching: First World Problems\n",
            "âœ… Wrote: First World Problems\n",
            "Fetching: Foil\n",
            "âœ… Wrote: Foil\n",
            "Fetching: Frank's 2000' TV\n",
            "âœ… Wrote: Frank's 2000' TV\n",
            "Fetching: Genius in France\n",
            "âœ… Wrote: Genius in France\n",
            "Fetching: Germs\n",
            "âœ… Wrote: Germs\n",
            "Fetching: Good Enough for Now\n",
            "âœ… Wrote: Good Enough for Now\n",
            "Fetching: Grapefruit Diet\n",
            "âœ… Wrote: Grapefruit Diet\n",
            "Fetching: Gump\n",
            "âœ… Wrote: Gump\n",
            "Fetching: Handy\n",
            "âœ… Wrote: Handy\n",
            "Fetching: Hardware Store\n",
            "âœ… Wrote: Hardware Store\n",
            "Fetching: Headline News\n",
            "âœ… Wrote: Headline News\n",
            "Fetching: I Can't Watch This\n",
            "âœ… Wrote: I Can't Watch This\n",
            "Fetching: I Love Rocky Road\n",
            "âœ… Wrote: I Love Rocky Road\n",
            "Fetching: I Lost on Jeopardy\n",
            "âœ… Wrote: I Lost on Jeopardy\n",
            "Fetching: I Remember Larry\n",
            "âœ… Wrote: I Remember Larry\n",
            "Fetching: I Think I'm a Clone Now\n",
            "âœ… Wrote: I Think I'm a Clone Now\n",
            "Fetching: I Want a New Duck\n",
            "âœ… Wrote: I Want a New Duck\n",
            "Fetching: I'll Sue Ya\n",
            "âœ… Wrote: I'll Sue Ya\n",
            "Fetching: If That Isn't Love\n",
            "âœ… Wrote: If That Isn't Love\n",
            "Fetching: Inactive\n",
            "âœ… Wrote: Inactive\n",
            "Fetching: It's All About the Pentiums\n",
            "âœ… Wrote: It's All About the Pentiums\n",
            "Fetching: Jackson Park Express\n",
            "âœ… Wrote: Jackson Park Express\n",
            "Fetching: Jerry Springer\n",
            "âœ… Wrote: Jerry Springer\n",
            "Fetching: Jurassic Park\n",
            "âœ… Wrote: Jurassic Park\n",
            "Fetching: King of Suede\n",
            "âœ… Wrote: King of Suede\n",
            "Fetching: Lasagna\n",
            "âœ… Wrote: Lasagna\n",
            "Fetching: Let Me Be Your Hog\n",
            "âœ… Wrote: Let Me Be Your Hog\n",
            "Fetching: Like a Surgeon\n",
            "âœ… Wrote: Like a Surgeon\n",
            "Fetching: Livin' in the Fridge\n",
            "âœ… Wrote: Livin' in the Fridge\n",
            "Fetching: Living with a Hernia\n",
            "âœ… Wrote: Living with a Hernia\n",
            "Fetching: Midnight Star\n",
            "âœ… Wrote: Midnight Star\n",
            "Fetching: Money for Nothing/Beverly Hillbillies*\n",
            "âŒ Not found: Money for Nothing/Beverly Hillbillies*\n",
            "Fetching: Mr. Frump in the Iron Lung\n",
            "âœ… Wrote: Mr. Frump in the Iron Lung\n",
            "Fetching: My Baby's in Love with Eddie Vedder\n",
            "âœ… Wrote: My Baby's in Love with Eddie Vedder\n",
            "Fetching: My Bologna\n",
            "âŒ Not found: My Bologna\n",
            "Fetching: My Own Eyes\n",
            "âœ… Wrote: My Own Eyes\n",
            "Fetching: Nature Trail to Hell\n",
            "âœ… Wrote: Nature Trail to Hell\n",
            "Fetching: One More Minute\n",
            "âœ… Wrote: One More Minute\n",
            "Fetching: Pancreas\n",
            "âœ… Wrote: Pancreas\n",
            "Fetching: Party at the Leper Colony\n",
            "âœ… Wrote: Party at the Leper Colony\n",
            "Fetching: Party in the CIA\n",
            "âœ… Wrote: Party in the CIA\n",
            "Fetching: Perform This Way\n",
            "âœ… Wrote: Perform This Way\n",
            "Fetching: Polka Face\n",
            "âœ… Wrote: Polka Face\n",
            "Fetching: Polka Your Eyes Out\n",
            "âœ… Wrote: Polka Your Eyes Out\n",
            "Fetching: Polkas on 45\n",
            "âœ… Wrote: Polkas on 45\n",
            "Fetching: Pretty Fly for a Rabbi\n",
            "âŒ Not found: Pretty Fly for a Rabbi\n",
            "Fetching: Ricky\n",
            "âœ… Wrote: Ricky\n",
            "Fetching: She Drives Like Crazy\n",
            "âœ… Wrote: She Drives Like Crazy\n",
            "Fetching: Skipper Dan\n",
            "âœ… Wrote: Skipper Dan\n",
            "Fetching: Smells Like Nirvana\n",
            "âœ… Wrote: Smells Like Nirvana\n",
            "Fetching: Spam\n",
            "âŒ Not found: Spam\n",
            "Fetching: Sports Song\n",
            "âœ… Wrote: Sports Song\n",
            "Fetching: Stop Forwarding That Crap to Me\n",
            "âœ… Wrote: Stop Forwarding That Crap to Me\n",
            "Fetching: Stuck in a Closet with Vanna White\n",
            "âœ… Wrote: Stuck in a Closet with Vanna White\n",
            "Fetching: Such a Groovy Guy\n",
            "âœ… Wrote: Such a Groovy Guy\n",
            "Fetching: Taco Grande\n",
            "âœ… Wrote: Taco Grande\n",
            "Fetching: Tacky\n",
            "âœ… Wrote: Tacky\n",
            "Fetching: Talk Soup\n",
            "âœ… Wrote: Talk Soup\n",
            "Fetching: The Alternative Polka\n",
            "âœ… Wrote: The Alternative Polka\n",
            "Fetching: The Biggest Ball of Twine in Minnesota\n",
            "âœ… Wrote: The Biggest Ball of Twine in Minnesota\n",
            "Fetching: The Check's in the Mail\n",
            "âœ… Wrote: The Check's in the Mail\n",
            "Fetching: The Hamilton Polka\n",
            "âœ… Wrote: The Hamilton Polka\n",
            "Fetching: The Night Santa Went Crazy\n",
            "âœ… Wrote: The Night Santa Went Crazy\n",
            "Fetching: The Plumbing Song\n",
            "âœ… Wrote: The Plumbing Song\n",
            "Fetching: The Saga Begins\n",
            "âœ… Wrote: The Saga Begins\n",
            "Fetching: The White Stuff\n",
            "âœ… Wrote: The White Stuff\n",
            "Fetching: This Is the Life\n",
            "âœ… Wrote: This Is the Life\n",
            "Fetching: Traffic Jam\n",
            "âœ… Wrote: Traffic Jam\n",
            "Fetching: Trapped in the Drive-Thru\n",
            "âŒ Not found: Trapped in the Drive-Thru\n",
            "Fetching: Trigger Happy\n",
            "âœ… Wrote: Trigger Happy\n",
            "Fetching: Twister\n",
            "âœ… Wrote: Twister\n",
            "Fetching: UHF\n",
            "âŒ Not found: UHF\n",
            "Fetching: Velvet Elvis\n",
            "âœ… Wrote: Velvet Elvis\n",
            "Fetching: Virus Alert\n",
            "âœ… Wrote: Virus Alert\n",
            "Fetching: Wanna B Ur Lovr\n",
            "âœ… Wrote: Wanna B Ur Lovr\n",
            "Fetching: Weasel Stomping Day\n",
            "âœ… Wrote: Weasel Stomping Day\n",
            "Fetching: Whatever You Like\n",
            "âœ… Wrote: Whatever You Like\n",
            "Fetching: When I Was Your Age\n",
            "âœ… Wrote: When I Was Your Age\n",
            "Fetching: White & Nerdy\n",
            "âœ… Wrote: White & Nerdy\n",
            "Fetching: Why Does This Always Happen to Me?\n",
            "âœ… Wrote: Why Does This Always Happen to Me?\n",
            "Fetching: Word Crimes\n",
            "âœ… Wrote: Word Crimes\n",
            "Fetching: You Don't Love Me Anymore\n",
            "âœ… Wrote: You Don't Love Me Anymore\n",
            "Fetching: Young, Dumb & Ugly\n",
            "âŒ Not found: Young, Dumb & Ugly\n",
            "Fetching: Your Horoscope for Today\n",
            "âœ… Wrote: Your Horoscope for Today\n",
            "Fetching: Yoda\n",
            "âœ… Wrote: Yoda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the previous defined functions to preprocessed the raw lyrics and use the Hugging Face transformers library to fine-tune GPT-2."
      ],
      "metadata": {
        "id": "XMj_SSil3p64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the file content\n",
        "with open(\"weird_al_lyrics.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    weird_al_lyrics_raw = f.read()\n",
        "\n",
        "# Preprocess the text\n",
        "weird_al_lyrics_clean = preprocess_lyrics(weird_al_lyrics_raw)\n",
        "\n",
        "# Fine-tune GPT-2\n",
        "fine_tune_gpt2(weird_al_lyrics_clean, \"weird_al_gpt2_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kj-dC_pR4jCg",
        "outputId": "70e3b15f-2eec-489f-91b4-f6702f51ee2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10990' max='10990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10990/10990 35:27, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>4.215900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.206100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>4.097800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.770700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.800400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.685900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.679900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.722300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.589700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.578600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.563800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>2.893000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>2.831200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>2.858200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.853400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>2.861200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>2.789200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>2.790900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>2.722500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.775700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>2.779900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>2.628000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>2.182400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>2.130100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>2.164800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>2.265400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>2.256600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>2.195100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>2.320100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>2.190800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>2.266000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>2.192400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>2.290000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>1.778300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.700500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>1.747700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>1.862400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>1.774400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>1.809400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.870200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>1.836900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>1.761000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>1.836800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>1.825600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.490500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>1.482000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>1.477200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>1.541500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>1.469200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.505000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>1.452100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>1.434300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>1.574300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>1.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.499200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>1.255900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>1.285400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>1.237300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>1.239300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.213300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>1.290800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>1.241900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>1.311300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>1.273700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>1.261400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>1.278700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>1.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>1.028800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>1.074200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.119900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>1.132600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>1.064300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>1.084800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>1.058300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>1.122700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>1.085700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>1.129400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.995000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.963400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.993600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>1.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.972300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.927000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.975000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.964200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.980600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>1.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.983600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.876100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.902800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.896200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.897700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.895200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.886900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.880800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.883600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.892000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.908500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.922600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.829000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.849400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.866700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.823200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.846700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.871300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.845700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10700</td>\n",
              "      <td>0.856000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.845900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10900</td>\n",
              "      <td>0.830100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved to: weird_al_gpt2_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will make some custom functions to generate Weird Al songs."
      ],
      "metadata": {
        "id": "gtfnOctY5RDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_as_weird_al_song(raw_text, lines_per_block=(3, 5)):\n",
        "    \"\"\"\n",
        "    Format generated text into a Weird Al-style song structure.\n",
        "\n",
        "    This function breaks the raw generated text into structured sections\n",
        "    commonly found in Weird Al-style songs, such as \"[Weird Fact]\" or\n",
        "    \"[Punchline]\", using line blocks of variable length.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    raw_text : str\n",
        "        The raw output from the language model.\n",
        "\n",
        "    lines_per_block : tuple of int, optional\n",
        "        A range (min, max) for how many lines appear in each song section.\n",
        "        Defaults to (3, 5).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        The formatted Weird Al-style song with section headers.\n",
        "    \"\"\"\n",
        "    # Split the text into structured lines and remove duplicate section labels\n",
        "    lines = split_into_lyric_lines(raw_text)\n",
        "    lines = clean_lyrics_lines(lines)\n",
        "\n",
        "    # Weird Al-style section labels with comedic/narrative flair\n",
        "    section_template = [\"[Verse 1]\", \"[Verse 2]\", \"[Weird Fact]\", \"[Bridge]\", \"[Punchline]\", \"[Outro]\"]\n",
        "\n",
        "    output = []\n",
        "    i = 0\n",
        "\n",
        "    # Loop through each song section and assign a random number of lines\n",
        "    for section in section_template:\n",
        "        block_size = random.randint(*lines_per_block)\n",
        "        block_lines = lines[i:i+block_size]\n",
        "\n",
        "        if not block_lines:\n",
        "            break\n",
        "\n",
        "        output.append(section)\n",
        "        output.extend(block_lines)\n",
        "        output.append(\"\")  # Add space between sections\n",
        "        i += block_size\n",
        "\n",
        "    return \"\\n\".join(output)\n",
        "\n",
        "\n",
        "def trim_repeated_words(text, limit=4):\n",
        "    \"\"\"\n",
        "    Detect and trim excessive repeated short words in text.\n",
        "\n",
        "    This function scans the input for any short word (2â€“5 characters) that\n",
        "    repeats consecutively beyond a given limit, and reduces it to two instances.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "        The text (typically model-generated lyrics) to be cleaned.\n",
        "\n",
        "    limit : int, optional\n",
        "        The number of consecutive repetitions allowed before trimming.\n",
        "        Default is 4.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Cleaned text with excessive short word repetitions trimmed.\n",
        "    \"\"\"\n",
        "    # Match any 2â€“5 letter word repeated more than `limit` times\n",
        "    pattern = r\"\\b(\\w{2,5})(\\s+\\1){\" + str(limit) + r\",}\\b\"\n",
        "\n",
        "    # Replace with just two repetitions\n",
        "    return re.sub(pattern, lambda m: f\"{m.group(1)} {m.group(1)}\", text, flags=re.IGNORECASE)\n",
        "\n",
        "\n",
        "\n",
        "def generate_weird_al_song(prompt=\"white and nerdy\", model_dir=\"weird_al_gpt2_model\",\n",
        "                           output_file=\"generated_weird_al_song.txt\", max_length=400, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generate a Weird Al-style song using a fine-tuned GPT-2 model.\n",
        "\n",
        "    This function takes an initial prompt and produces a formatted comedic\n",
        "    song by generating text from a fine-tuned GPT-2 model and structuring\n",
        "    the output into custom song sections.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    prompt : str, optional\n",
        "        Initial seed phrase to guide the song generation. Default is\n",
        "        \"white and nerdy\".\n",
        "\n",
        "    model_dir : str\n",
        "        Path to the fine-tuned GPT-2 model directory.\n",
        "\n",
        "    output_file : str\n",
        "        Destination file path to save the generated song.\n",
        "\n",
        "    max_length : int, optional\n",
        "        Maximum number of tokens to generate. Default is 400.\n",
        "\n",
        "    temperature : float, optional\n",
        "        Sampling temperature for text generation. Higher values produce\n",
        "        more randomness. Default is 1.0.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Load model and tokenizer from fine-tuned directory\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_dir)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
        "    model.eval()\n",
        "\n",
        "    # Move model to GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "        model.to(\"cuda\")\n",
        "\n",
        "    # Tokenize the prompt input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        input_ids = input_ids.to(\"cuda\")\n",
        "        attention_mask = attention_mask.to(\"cuda\")\n",
        "\n",
        "    # Generate song lyrics from the model\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=temperature,\n",
        "            repetition_penalty=1.5,\n",
        "            num_return_sequences=1,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode generated tokens into text and clean up any excessive repetition\n",
        "    raw_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    clean_text = trim_repetition(raw_text, limit=1)\n",
        "    clean_text = trim_repeated_words(clean_text, limit=1)\n",
        "    formatted_song = format_as_weird_al_song(raw_text)\n",
        "\n",
        "    # Save the song to file\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(formatted_song)\n",
        "\n",
        "    print(f\"âœ… Weird Al-style song saved to '{output_file}'\\n\")\n",
        "    print(\"ðŸŽ¤ The song:\\n\")\n",
        "    print(formatted_song)"
      ],
      "metadata": {
        "id": "IjvwmVUn5VGC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then generate three Weird Al songs."
      ],
      "metadata": {
        "id": "DakRD2_B5ga1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_weird_al_song(\n",
        "    prompt=\"I like earl grey tea and minesweeper\",\n",
        "    model_dir=\"weird_al_gpt2_model\",\n",
        "    output_file=\"my_weird_al_song.txt\",\n",
        "    max_length=500,\n",
        "    temperature=0.5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEnZh40E5nuL",
        "outputId": "daefb951-b678-41d0-e6c1-57c7e4ba838d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Weird Al-style song saved to 'my_weird_al_song.txt'\n",
            "\n",
            "ðŸŽ¤ The song:\n",
            "\n",
            "[Verse 1]\n",
            "I like earl grey tea and minesweeper hamster bells ooh\n",
            "hoo hoonie helicopters yah i like zelda's song 'cause i\n",
            "love to dance like a leper colony on st trope\n",
            "\n",
            "[Verse 2]\n",
            "oh yeah ethel gone well heh heh sheh baby don't\n",
            "you know it lucy too much time in the sun\n",
            "when my family is playing jolly oldies game of ping\n",
            "\n",
            "[Weird Fact]\n",
            "pong at the beach ooow woo hoot wangee hey ho\n",
            "hoo hooray for that eddie vedder mny buddy now you\n",
            "go out with me haw tullys day and night like\n",
            "your parents gonna kick us down the stairs ah right\n",
            "before dawn today they wanna tear us apart oh no\n",
            "\n",
            "[Bridge]\n",
            "we can never play this game of ping pols again\n",
            "let them rip our brains out into ribbons just so\n",
            "badly they won' break their necks cause they found some\n",
            "new way ta beat the game of hockey yeah what\n",
            "\n",
            "[Punchline]\n",
            "do ya want darlin' dingbat man back home runnin over\n",
            "his head twice as hard as nails but he still\n",
            "gettin' gold star for that very first time here come\n",
            "those electric guitars blowin' lots upon tonsauce all over town\n",
            "hall oughta melt your brain shut up and throw away\n",
            "\n",
            "[Outro]\n",
            "everything you owned ever got if only you could lend\n",
            "somebody something nice instead ricky sha la ba ba ba\n",
            "ba ba ba ba ba ba bow dippity belt minute\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_weird_al_song(\n",
        "    prompt=\"I never wear buttons but I got a cool hat\",\n",
        "    model_dir=\"weird_al_gpt2_model\",\n",
        "    output_file=\"my_weird_al_song_2.txt\",\n",
        "    max_length=500,\n",
        "    temperature=0.7\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kedcl-5p7LrW",
        "outputId": "da7edba4-7652-4e46-f628-d3a39dd9a88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Weird Al-style song saved to 'my_weird_al_song_2.txt'\n",
            "\n",
            "ðŸŽ¤ The song:\n",
            "\n",
            "[Verse 1]\n",
            "I never wear buttons but I got a cool hat\n",
            "that said twine baller even if you didn't win the\n",
            "grand prize just a year ago yeah it's in my\n",
            "national library at china i guess that ties me to\n",
            "\n",
            "[Verse 2]\n",
            "nature trailblazer forever ooh hoo hoot hah hooray it makes\n",
            "me kinda wanna runnin' yeshope somebody tries ta loot my\n",
            "hard drive this week hey yoda ya know what else\n",
            "am i supposed not to do lucy too luke don't\n",
            "want no crummy music for you like some twisted band\n",
            "\n",
            "[Weird Fact]\n",
            "of madonna gettin' paid for their lousy shows mr frump\n",
            "is an old man with a bad case eighty pounds\n",
            "body odor and he talks smack dab dabba every night\n",
            "\n",
            "[Bridge]\n",
            "till dawn 'till dawn come day dawn finally i'm gonna\n",
            "be a star witness on camera prove they're nazi all\n",
            "right now remember when they put up those giant display\n",
            "gates cause we lost our tails yesterday afternoon gavin' jack\n",
            "\n",
            "[Punchline]\n",
            "flash and everybody was jerry springering ricky huh woo woo\n",
            "woo oh waddlin' around the house tonight ah midnight star\n",
            "i wanna see how jealous she'll havetobe tyo hear from\n",
            "\n",
            "[Outro]\n",
            "you later today whoa listenin' here baby let us scream\n",
            "while screaming in unison across village krakatoa oh wanna sing\n",
            "along beside him snorting pixie sticks and shrieking incoherently over\n",
            "spilled milk ice cream cones woofie jammin laden towers dippity\n",
            "bombs loaded weapons packed into rambo shaped wedges minute hand\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_weird_al_song(\n",
        "    prompt=\"Our stats are thoroughly impressive\",\n",
        "    model_dir=\"weird_al_gpt2_model\",\n",
        "    output_file=\"my_weird_al_song_3.txt\",\n",
        "    max_length=500,\n",
        "    temperature=0.6\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxgAABx9FSxy",
        "outputId": "5590d10d-2114-4665-9b2f-3f1da874c9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Weird Al-style song saved to 'my_weird_al_song_3.txt'\n",
            "\n",
            "ðŸŽ¤ The song:\n",
            "\n",
            "[Verse 1]\n",
            "Our stats are thoroughly impressive we're second only to mighty\n",
            "hot sauce champion mizouse nazi favorito by a hefty 3x\n",
            "gold mine worth of diamonds and an icecold keg from\n",
            "\n",
            "[Verse 2]\n",
            "our neighbor's pet store oh yeah you should check it\n",
            "out don't forget that we've got tons of fun in\n",
            "return for your hardy stare after dinner tonight at the\n",
            "steakhouse forty miles wide wide wide wide wide wide hole\n",
            "\n",
            "[Weird Fact]\n",
            "in the ground next door is completely covered with dental\n",
            "floss and cracked glass shards everywhere i go see 'em\n",
            "playin' hockey on thirty percent off sale now right here\n",
            "in this lousy windhampton hamlin state half as much money\n",
            "\n",
            "[Bridge]\n",
            "as any other business in town makes in excessofpremiums today\n",
            "thanks so very highly ladenly diane why you gotta pay\n",
            "for what little junk they sell us on ebay well\n",
            "you know they really suck no matter how good their\n",
            "\n",
            "[Punchline]\n",
            "food grade cling wrap isn drivin' competition just like yoda\n",
            "hey whoa listen up mommy let's make this place better\n",
            "than kabob bonjour again tomorrow night when he kicks butt\n",
            "into smithereens twenty feet deep over 300 yards wide pitiful\n",
            "rocky denuco room temperature rise 34 degrees below zero gravity\n",
            "\n",
            "[Outro]\n",
            "barely able to melt snow without breaking a sweat dr\n",
            "omgle sue won every major sports series since july 2000\n",
            "ah yesterday evening en route home three hours late for\n",
            "my algebra test tube rerunninja never fought his iron lung\n",
            "before finally being knocked down two blocks short last week\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Green Day Song Generator"
      ],
      "metadata": {
        "id": "ZlNt6D0cg32A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a third example, we generate songs from the band [Green Day](https://en.wikipedia.org/wiki/Green_Day)."
      ],
      "metadata": {
        "id": "G0_FJN9TiPr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "green_day_songs = [\n",
        "    \"21 Guns\",\n",
        "    \"2000 Light Years Away\",\n",
        "    \"80\",\n",
        "    \"86\",\n",
        "    \"American Idiot\",\n",
        "    \"Android\",\n",
        "    \"Are We the Waiting\",\n",
        "    \"Armatage Shanks\",\n",
        "    \"At the Library\",\n",
        "    \"Basket Case\",\n",
        "    \"Before the Lobotomy\",\n",
        "    \"Blood, Sex and Booze\",\n",
        "    \"Boulevard of Broken Dreams\",\n",
        "    \"Brain Stew\",\n",
        "    \"Brat\",\n",
        "    \"Christie Road\",\n",
        "    \"Church on Sunday\",\n",
        "    \"Coming Clean\",\n",
        "    \"Deadbeat Holiday\",\n",
        "    \"Disappearing Boy\",\n",
        "    \"Dominated Love Slave\",\n",
        "    \"Don't Leave Me\",\n",
        "    \"East Jesus Nowhere\",\n",
        "    \"Emenius Sleepus\",\n",
        "    \"Extraordinary Girl\",\n",
        "    \"F.O.D.\",\n",
        "    \"Fashion Victim\",\n",
        "    \"Favorite Son\",\n",
        "    \"Geek Stink Breath\",\n",
        "    \"Give Me Novacaine\",\n",
        "    \"Good Riddance (Time of Your Life)\",\n",
        "    \"Green Day\",\n",
        "    \"Haushinka\",\n",
        "    \"Hitchin' a Ride\",\n",
        "    \"Hold On\",\n",
        "    \"Holiday\",\n",
        "    \"Homecoming\",\n",
        "    \"Horseshoes and Handgrenades\",\n",
        "    \"I Fought the Law\",\n",
        "    \"I Want to Be Alone\",\n",
        "    \"I Want to Be on TV\",\n",
        "    \"In the End\",\n",
        "    \"J.A.R. (Jason Andrew Relva)\",\n",
        "    \"Jackass\",\n",
        "    \"Jaded\",\n",
        "    \"Jesus of Suburbia\",\n",
        "    \"King for a Day\",\n",
        "    \"Know Your Enemy\",\n",
        "    \"Last Night on Earth\",\n",
        "    \"Last of the American Girls\",\n",
        "    \"Letterbomb\",\n",
        "    \"Longview\",\n",
        "    \"Macy's Day Parade\",\n",
        "    \"Maria\",\n",
        "    \"Minority\",\n",
        "    \"Misery\",\n",
        "    \"Nice Guys Finish Last\",\n",
        "    \"No One Knows\",\n",
        "    \"Nuclear Family\",\n",
        "    \"One for the Razorbacks\",\n",
        "    \"Only of You\",\n",
        "    \"Panic Song\",\n",
        "    \"Paper Lanterns\",\n",
        "    \"Peacemaker\",\n",
        "    \"Platypus (I Hate You)\",\n",
        "    \"Poprocks & Coke\",\n",
        "    \"Prosthetic Head\",\n",
        "    \"Pulling Teeth\",\n",
        "    \"Redundant\",\n",
        "    \"Restless Heart Syndrome\",\n",
        "    \"Revolution Radio\",\n",
        "    \"Road to Acceptance\",\n",
        "    \"Scattered\",\n",
        "    \"She\",\n",
        "    \"St. Jimmy\",\n",
        "    \"Still Breathing\",\n",
        "    \"Stuck with Me\",\n",
        "    \"Stuart and the Ave.\",\n",
        "    \"Take Back\",\n",
        "    \"The Forgotten\",\n",
        "    \"The Grouch\",\n",
        "    \"The Judge's Daughter\",\n",
        "    \"The One I Want\",\n",
        "    \"The Static Age\",\n",
        "    \"The Time of Your Life (Good Riddance)\",\n",
        "    \"Tight Wad Hill\",\n",
        "    \"Troublemaker\",\n",
        "    \"Uptight\",\n",
        "    \"Waiting\",\n",
        "    \"Wake Me Up When September Ends\",\n",
        "    \"Walking Alone\",\n",
        "    \"Walking Contradiction\",\n",
        "    \"Warning\",\n",
        "    \"Welcome to Paradise\",\n",
        "    \"Westbound Sign\",\n",
        "    \"Whatsername\",\n",
        "    \"When I Come Around\",\n",
        "    \"Who Wrote Holden Caulfield?\",\n",
        "    \"Why Do You Want Him?\",\n",
        "    \"Worry Rock\",\n",
        "    \"X-Kid\",\n",
        "    \"You Lied\"\n",
        "]"
      ],
      "metadata": {
        "id": "HGnNsT-aiVjj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then write the text and title of those songs into a text file."
      ],
      "metadata": {
        "id": "fjyruAZZjqWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = os.path.abspath(\"green_day_lyrics.txt\")\n",
        "print(f\"Writing lyrics to: {output_path}\")\n",
        "\n",
        "with open(\"green_day_lyrics.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for title in green_day_songs:\n",
        "        print(f\"Fetching: {title}\")\n",
        "        lyrics = get_lyrics(\"Green Day\", title)\n",
        "\n",
        "        if lyrics:\n",
        "            f.write(f\"### {title} ###\\n{lyrics}\\n\\n\")\n",
        "            print(f\"âœ… Wrote: {title}\")\n",
        "        else:\n",
        "            f.write(f\"### {title} ###\\nLyrics not found.\\n\\n\")\n",
        "            print(f\"âŒ Not found: {title}\")\n",
        "        time.sleep(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVtPSkNujs8g",
        "outputId": "cba2ba1b-1940-4fee-ac0c-e291922ab3b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lyrics to: /content/green_day_lyrics.txt\n",
            "Fetching: 21 Guns\n",
            "âœ… Wrote: 21 Guns\n",
            "Fetching: 2000 Light Years Away\n",
            "âœ… Wrote: 2000 Light Years Away\n",
            "Fetching: 80\n",
            "âœ… Wrote: 80\n",
            "Fetching: 86\n",
            "âœ… Wrote: 86\n",
            "Fetching: American Idiot\n",
            "âœ… Wrote: American Idiot\n",
            "Fetching: Android\n",
            "âœ… Wrote: Android\n",
            "Fetching: Are We the Waiting\n",
            "âœ… Wrote: Are We the Waiting\n",
            "Fetching: Armatage Shanks\n",
            "âœ… Wrote: Armatage Shanks\n",
            "Fetching: At the Library\n",
            "âœ… Wrote: At the Library\n",
            "Fetching: Basket Case\n",
            "âœ… Wrote: Basket Case\n",
            "Fetching: Before the Lobotomy\n",
            "âœ… Wrote: Before the Lobotomy\n",
            "Fetching: Blood, Sex and Booze\n",
            "âŒ Not found: Blood, Sex and Booze\n",
            "Fetching: Boulevard of Broken Dreams\n",
            "âœ… Wrote: Boulevard of Broken Dreams\n",
            "Fetching: Brain Stew\n",
            "âœ… Wrote: Brain Stew\n",
            "Fetching: Brat\n",
            "âœ… Wrote: Brat\n",
            "Fetching: Christie Road\n",
            "âœ… Wrote: Christie Road\n",
            "Fetching: Church on Sunday\n",
            "âœ… Wrote: Church on Sunday\n",
            "Fetching: Coming Clean\n",
            "âœ… Wrote: Coming Clean\n",
            "Fetching: Deadbeat Holiday\n",
            "âœ… Wrote: Deadbeat Holiday\n",
            "Fetching: Disappearing Boy\n",
            "âœ… Wrote: Disappearing Boy\n",
            "Fetching: Dominated Love Slave\n",
            "âœ… Wrote: Dominated Love Slave\n",
            "Fetching: Don't Leave Me\n",
            "âœ… Wrote: Don't Leave Me\n",
            "Fetching: East Jesus Nowhere\n",
            "âœ… Wrote: East Jesus Nowhere\n",
            "Fetching: Emenius Sleepus\n",
            "âœ… Wrote: Emenius Sleepus\n",
            "Fetching: Extraordinary Girl\n",
            "âœ… Wrote: Extraordinary Girl\n",
            "Fetching: F.O.D.\n",
            "âŒ Not found: F.O.D.\n",
            "Fetching: Fashion Victim\n",
            "âœ… Wrote: Fashion Victim\n",
            "Fetching: Favorite Son\n",
            "âœ… Wrote: Favorite Son\n",
            "Fetching: Geek Stink Breath\n",
            "âœ… Wrote: Geek Stink Breath\n",
            "Fetching: Give Me Novacaine\n",
            "âœ… Wrote: Give Me Novacaine\n",
            "Fetching: Good Riddance (Time of Your Life)\n",
            "âœ… Wrote: Good Riddance (Time of Your Life)\n",
            "Fetching: Green Day\n",
            "âœ… Wrote: Green Day\n",
            "Fetching: Haushinka\n",
            "âœ… Wrote: Haushinka\n",
            "Fetching: Hitchin' a Ride\n",
            "âœ… Wrote: Hitchin' a Ride\n",
            "Fetching: Hold On\n",
            "âœ… Wrote: Hold On\n",
            "Fetching: Holiday\n",
            "âœ… Wrote: Holiday\n",
            "Fetching: Homecoming\n",
            "âœ… Wrote: Homecoming\n",
            "Fetching: Horseshoes and Handgrenades\n",
            "âœ… Wrote: Horseshoes and Handgrenades\n",
            "Fetching: I Fought the Law\n",
            "âœ… Wrote: I Fought the Law\n",
            "Fetching: I Want to Be Alone\n",
            "âœ… Wrote: I Want to Be Alone\n",
            "Fetching: I Want to Be on TV\n",
            "âœ… Wrote: I Want to Be on TV\n",
            "Fetching: In the End\n",
            "âœ… Wrote: In the End\n",
            "Fetching: J.A.R. (Jason Andrew Relva)\n",
            "âŒ Not found: J.A.R. (Jason Andrew Relva)\n",
            "Fetching: Jackass\n",
            "âœ… Wrote: Jackass\n",
            "Fetching: Jaded\n",
            "âœ… Wrote: Jaded\n",
            "Fetching: Jesus of Suburbia\n",
            "âœ… Wrote: Jesus of Suburbia\n",
            "Fetching: King for a Day\n",
            "âœ… Wrote: King for a Day\n",
            "Fetching: Know Your Enemy\n",
            "âœ… Wrote: Know Your Enemy\n",
            "Fetching: Last Night on Earth\n",
            "âœ… Wrote: Last Night on Earth\n",
            "Fetching: Last of the American Girls\n",
            "âœ… Wrote: Last of the American Girls\n",
            "Fetching: Letterbomb\n",
            "âœ… Wrote: Letterbomb\n",
            "Fetching: Longview\n",
            "âœ… Wrote: Longview\n",
            "Fetching: Macy's Day Parade\n",
            "âœ… Wrote: Macy's Day Parade\n",
            "Fetching: Maria\n",
            "âœ… Wrote: Maria\n",
            "Fetching: Minority\n",
            "âœ… Wrote: Minority\n",
            "Fetching: Misery\n",
            "âœ… Wrote: Misery\n",
            "Fetching: Nice Guys Finish Last\n",
            "âœ… Wrote: Nice Guys Finish Last\n",
            "Fetching: No One Knows\n",
            "âœ… Wrote: No One Knows\n",
            "Fetching: Nuclear Family\n",
            "âœ… Wrote: Nuclear Family\n",
            "Fetching: One for the Razorbacks\n",
            "âœ… Wrote: One for the Razorbacks\n",
            "Fetching: Only of You\n",
            "âœ… Wrote: Only of You\n",
            "Fetching: Panic Song\n",
            "âœ… Wrote: Panic Song\n",
            "Fetching: Paper Lanterns\n",
            "âœ… Wrote: Paper Lanterns\n",
            "Fetching: Peacemaker\n",
            "âœ… Wrote: Peacemaker\n",
            "Fetching: Platypus (I Hate You)\n",
            "âœ… Wrote: Platypus (I Hate You)\n",
            "Fetching: Poprocks & Coke\n",
            "âœ… Wrote: Poprocks & Coke\n",
            "Fetching: Prosthetic Head\n",
            "âœ… Wrote: Prosthetic Head\n",
            "Fetching: Pulling Teeth\n",
            "âœ… Wrote: Pulling Teeth\n",
            "Fetching: Redundant\n",
            "âœ… Wrote: Redundant\n",
            "Fetching: Restless Heart Syndrome\n",
            "âœ… Wrote: Restless Heart Syndrome\n",
            "Fetching: Revolution Radio\n",
            "âœ… Wrote: Revolution Radio\n",
            "Fetching: Road to Acceptance\n",
            "âœ… Wrote: Road to Acceptance\n",
            "Fetching: Scattered\n",
            "âœ… Wrote: Scattered\n",
            "Fetching: She\n",
            "âœ… Wrote: She\n",
            "Fetching: St. Jimmy\n",
            "âœ… Wrote: St. Jimmy\n",
            "Fetching: Still Breathing\n",
            "âœ… Wrote: Still Breathing\n",
            "Fetching: Stuck with Me\n",
            "âœ… Wrote: Stuck with Me\n",
            "Fetching: Stuart and the Ave.\n",
            "âœ… Wrote: Stuart and the Ave.\n",
            "Fetching: Take Back\n",
            "âœ… Wrote: Take Back\n",
            "Fetching: The Forgotten\n",
            "âœ… Wrote: The Forgotten\n",
            "Fetching: The Grouch\n",
            "âœ… Wrote: The Grouch\n",
            "Fetching: The Judge's Daughter\n",
            "âœ… Wrote: The Judge's Daughter\n",
            "Fetching: The One I Want\n",
            "âœ… Wrote: The One I Want\n",
            "Fetching: The Static Age\n",
            "âœ… Wrote: The Static Age\n",
            "Fetching: The Time of Your Life (Good Riddance)\n",
            "âŒ Not found: The Time of Your Life (Good Riddance)\n",
            "Fetching: Tight Wad Hill\n",
            "âœ… Wrote: Tight Wad Hill\n",
            "Fetching: Troublemaker\n",
            "âœ… Wrote: Troublemaker\n",
            "Fetching: Uptight\n",
            "âœ… Wrote: Uptight\n",
            "Fetching: Waiting\n",
            "âœ… Wrote: Waiting\n",
            "Fetching: Wake Me Up When September Ends\n",
            "âœ… Wrote: Wake Me Up When September Ends\n",
            "Fetching: Walking Alone\n",
            "âœ… Wrote: Walking Alone\n",
            "Fetching: Walking Contradiction\n",
            "âœ… Wrote: Walking Contradiction\n",
            "Fetching: Warning\n",
            "âœ… Wrote: Warning\n",
            "Fetching: Welcome to Paradise\n",
            "âœ… Wrote: Welcome to Paradise\n",
            "Fetching: Westbound Sign\n",
            "âœ… Wrote: Westbound Sign\n",
            "Fetching: Whatsername\n",
            "âœ… Wrote: Whatsername\n",
            "Fetching: When I Come Around\n",
            "âœ… Wrote: When I Come Around\n",
            "Fetching: Who Wrote Holden Caulfield?\n",
            "âœ… Wrote: Who Wrote Holden Caulfield?\n",
            "Fetching: Why Do You Want Him?\n",
            "âœ… Wrote: Why Do You Want Him?\n",
            "Fetching: Worry Rock\n",
            "âœ… Wrote: Worry Rock\n",
            "Fetching: X-Kid\n",
            "âœ… Wrote: X-Kid\n",
            "Fetching: You Lied\n",
            "âœ… Wrote: You Lied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the previous defined functions to preprocessed the raw lyrics and use the Hugging Face transformers library to fine-tune GPT-2."
      ],
      "metadata": {
        "id": "YEJQSUY1kF2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the file content\n",
        "with open(\"green_day_lyrics.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    green_day_lyrics_raw = f.read()\n",
        "\n",
        "# Preprocess the text\n",
        "green_day_lyrics_clean = preprocess_lyrics(green_day_lyrics_raw)\n",
        "\n",
        "# Fine-tune GPT-2\n",
        "fine_tune_gpt2(green_day_lyrics_clean, \"green_day_gpt2_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iXAC-suVkIPr",
        "outputId": "ce9e1b9d-bd91-4f87-98d3-aa56064a6017"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6210' max='6210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6210/6210 21:20, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>4.094900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.701800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.517500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.486800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.214700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.261700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>2.685900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>2.387900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>2.345500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.361700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>2.340900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>2.262900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.925000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.716200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.725700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.705600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.660200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.638800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>1.609800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.272300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.317400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>1.386400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>1.358900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>1.265500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.271800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>1.026100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>1.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>1.114600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>1.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.078700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>1.097600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.905500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.911800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.913500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.901600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.966300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.916500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.868000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.836400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.843000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.825900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.815100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.838100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.787700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.718300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.752000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.778800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.772500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.811100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.797500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.695000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.698400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.710800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.726000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.726600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.747900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.670600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.703800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.676300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.671900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.688000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.690100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved to: green_day_gpt2_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before, we make some custom functions to generate Green Day songs."
      ],
      "metadata": {
        "id": "HuU9U33Nkzew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_as_green_day_song(raw_text, lines_per_block=(4, 6)):\n",
        "    \"\"\"\n",
        "    Format generated text into a structured Green Day-style song.\n",
        "\n",
        "    Cleans and splits raw model output into sections mimicking a Green Day track:\n",
        "    Verse, Chorus, Bridge, Outro. Automatically trims broken phrases and uses\n",
        "    variable-length blocks to mimic human-written structure.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    raw_text : str\n",
        "        Unformatted text output from the language model.\n",
        "\n",
        "    lines_per_block : tuple of int, optional\n",
        "        The (min, max) range of line counts per section block. Default is (4, 6).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        The cleaned and formatted lyrics with labeled song sections.\n",
        "    \"\"\"\n",
        "    lines = split_into_lyric_lines(raw_text)\n",
        "    lines = clean_lyrics_lines(lines)\n",
        "\n",
        "    # Remove junk lines (e.g., single-word lines or malformed tokens)\n",
        "    lines = [\n",
        "        l for l in lines\n",
        "        if len(l.split()) >= 3 and not re.search(r\"[^\\w\\s']\", l)\n",
        "    ]\n",
        "\n",
        "    section_template = [\n",
        "        \"[Verse 1]\", \"[Chorus]\", \"[Verse 2]\",\n",
        "        \"[Chorus]\", \"[Bridge]\", \"[Chorus]\", \"[Outro]\"\n",
        "    ]\n",
        "\n",
        "    output = []\n",
        "    i = 0\n",
        "\n",
        "    for section in section_template:\n",
        "        block_size = random.randint(*lines_per_block)\n",
        "        block_lines = lines[i:i + block_size]\n",
        "\n",
        "        # If there arenâ€™t enough lines left, finish early\n",
        "        if len(block_lines) < 2:\n",
        "            break\n",
        "\n",
        "        output.append(section)\n",
        "        output.extend(block_lines)\n",
        "        output.append(\"\")  # Add blank line between sections\n",
        "        i += block_size\n",
        "\n",
        "    return \"\\n\".join(output)\n",
        "\n",
        "def generate_green_day_song(prompt=\"i walk this lonely road\", model_dir=\"green_day_gpt2_model\",\n",
        "                          output_file=\"generated_green_day_song.txt\", max_length=400, temperature=0.95):\n",
        "  \"\"\"\n",
        "  Generate a Green Day-style song using a fine-tuned GPT-2 model.\n",
        "\n",
        "  This function takes a prompt and generates structured lyrics in the\n",
        "  style of Green Day. The lyrics are formatted into song sections and\n",
        "  repetitive phrases are trimmed.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  prompt : str, optional\n",
        "      A seed phrase to guide the song generation. Default is\n",
        "      \"i walk this lonely road\".\n",
        "\n",
        "  model_dir : str\n",
        "      Directory path to the fine-tuned Green Day GPT-2 model.\n",
        "\n",
        "  output_file : str\n",
        "      File path where the generated song will be saved.\n",
        "\n",
        "  max_length : int, optional\n",
        "      Maximum number of tokens to generate. Default is 400.\n",
        "\n",
        "  temperature : float, optional\n",
        "      Sampling temperature. Higher values result in more randomness.\n",
        "      Default is 0.95.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  # Load the tokenizer and model\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(model_dir)\n",
        "  model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
        "  model.eval()\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      model.to(\"cuda\")\n",
        "\n",
        "  # Tokenize input prompt\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "  input_ids = inputs[\"input_ids\"]\n",
        "  attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      input_ids = input_ids.to(\"cuda\")\n",
        "      attention_mask = attention_mask.to(\"cuda\")\n",
        "\n",
        "  # Generate lyrics\n",
        "  with torch.no_grad():\n",
        "      output = model.generate(\n",
        "          input_ids=input_ids,\n",
        "          attention_mask=attention_mask,\n",
        "          max_length=max_length,\n",
        "          do_sample=True,\n",
        "          top_k=50,\n",
        "          top_p=0.95,\n",
        "          temperature=temperature,\n",
        "          repetition_penalty=1.5,\n",
        "          num_return_sequences=1,\n",
        "          pad_token_id=tokenizer.eos_token_id\n",
        "      )\n",
        "\n",
        "  # Clean up the output\n",
        "  raw_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  clean_text = trim_repetition(raw_text, limit=1)\n",
        "  clean_text = trim_repeated_words(clean_text, limit=1)\n",
        "  formatted_song = format_as_green_day_song(clean_text)\n",
        "\n",
        "  # Save to file\n",
        "  with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "      f.write(formatted_song)\n",
        "\n",
        "  print(f\"âœ… Green Day-style song saved to '{output_file}'\\n\")\n",
        "  print(\"ðŸŽ¤ The song:\\n\")\n",
        "  print(formatted_song)"
      ],
      "metadata": {
        "id": "RVPTJnyOk4eK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then create two new Green Day songs."
      ],
      "metadata": {
        "id": "QiwHB1welZ3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_green_day_song(\n",
        "    prompt=\"In the summertime\",\n",
        "    model_dir=\"green_day_gpt2_model\",\n",
        "    output_file=\"my_green_day_song.txt\",\n",
        "    max_length=500,\n",
        "    temperature=0.85\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0tInAbaldAW",
        "outputId": "e713080e-22c0-4538-96a8-557fea33c82a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Green Day-style song saved to 'my_green_day_song.txt'\n",
            "\n",
            "ðŸŽ¤ The song:\n",
            "\n",
            "[Verse 1]\n",
            "In the summertime revolution dance on eggshells in my old\n",
            "stomping ground yet i can't seem to get up and\n",
            "walk away from you it seems like forever ago just\n",
            "for a bit of fun again daddy threw me out\n",
            "here's some loose ends so don your not in shape\n",
            "\n",
            "[Chorus]\n",
            "now momma ain gotta clean house hey dad got somethin'\n",
            "going on but no one likes ya mother damn well\n",
            "did because she love wasin' around before he went crazy\n",
            "yeah yeah what do you think about momma getting mad\n",
            "\n",
            "[Verse 2]\n",
            "at daddy whatsername is really all that i need right\n",
            "now isnthe last moment thats gonna happen cause everything belongs\n",
            "toyou alright boy am i retarded son dont know how\n",
            "man made this decision okay maybe if you wanna leave\n",
            "me alone then why ohwhy should anyone care baby look\n",
            "into my eyesight as they snotfilled their brains up with\n",
            "\n",
            "[Chorus]\n",
            "lies once again young man learned to live by his\n",
            "own rules good riddance time new york city lights come\n",
            "on parade down under the stars tonight night vinnie croaked\n",
            "through my mind sometimes times cause where might it be\n",
            "headed we go nowhere fast but never forget our purpose\n",
            "\n",
            "[Bridge]\n",
            "wise long lost enemies are gone something in the past\n",
            "will rise tomorrow nothing ever comes back together when faced\n",
            "against its maker please keep adding twists coming forward sure\n",
            "does make people happy older brother may have strange habitsbut\n",
            "always keeps changing even when caught dumb it only deepens\n",
            "\n",
            "[Chorus]\n",
            "the truth behind the laughter still tryingto find its way\n",
            "to christie roadster hey there kid ran across some problems\n",
            "father thought someone else found him nice little helper st\n",
            "jimmy won an argument over the edge of joking matter\n",
            "the wrist holds you ransom in gold beengarbled tight ends\n",
            "in heathen hillary hey guys havin' fun remember to pay\n",
            "\n",
            "[Outro]\n",
            "respect to yourself parent told me wrong didn 'cause nobody\n",
            "loves you ive turned sour haven gina hit the road\n",
            "running out of tricks hide in a ditch whelming hot\n",
            "tub sunday special hey patreon goes straight red blooded amsterdam\n",
            "perfected cops car crash victim hey watch catch some action\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_green_day_song(\n",
        "    prompt=\"it is no longer cold outside\",\n",
        "    model_dir=\"green_day_gpt2_model\",\n",
        "    output_file=\"my_green_day_song_2.txt\",\n",
        "    max_length=500,\n",
        "    temperature=0.4\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQgkfPPVleYO",
        "outputId": "be9003b3-285d-49e6-8aeb-b0aa37a51fb5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Green Day-style song saved to 'my_green_day_song_2.txt'\n",
            "\n",
            "ðŸŽ¤ The song:\n",
            "\n",
            "[Verse 1]\n",
            "it is no longer cold outside and it's now your\n",
            "favorite haunt with its resident assassin known as the assassin\n",
            "queen bee st jimmy hey yeah yeah i'm a nag\n",
            "shitface yeah yeah i walk alone sometimes even get drunk\n",
            "on my knees before going away maybe hitch a ride\n",
            "to someplace nice gettin' hot again daddy ain't got none\n",
            "\n",
            "[Chorus]\n",
            "right don you're not so clean looking but he's still\n",
            "getting lazy oh well thats what we used to call\n",
            "our lives just like dad was hey whatsername whatsername whatsername\n",
            "whatsitter whatsittingername whatsingle allthepeople that you know isnt really his\n",
            "\n",
            "[Verse 2]\n",
            "name dont you exist because of you nobody knows where\n",
            "maria went wrong hey she disappeared in 2000 miles an\n",
            "hour ago why didshe go nowhere fast enough for christie\n",
            "roadster hey lookin sharp man someting isgethernowhere something else entirely\n",
            "different now pathetically left without any trace due diligence nothing\n",
            "\n",
            "[Chorus]\n",
            "new found cause there's only one thing keeping me up\n",
            "at night time sureknock knock yourself out hardcoded murder coded\n",
            "suicide code redneck white trash america hey howdy do you\n",
            "look good dressed down under black eye catching color me\n",
            "\n",
            "[Bridge]\n",
            "stupid yeah yeah alright then let's face it when faced\n",
            "with reality check whatsername whatsolution whatsername whatsirite whatsername whatsmurder proof\n",
            "everything worth trying once thought never made sense whatshooting whatsiscause\n",
            "if anyone can hear me slap somesense into me this\n",
            "\n",
            "[Chorus]\n",
            "won be solved someday soon enough will probably suffice excuse\n",
            "myself hey gotta have fun keep running amsterdam hey wanna\n",
            "kill some people hey they weren 't real men these\n",
            "daysare gone hey wear their shit together old boy ran\n",
            "\n",
            "[Outro]\n",
            "them through speedo gun hey damnit's bulletproof haven been broken\n",
            "yet here goes nothing more than joe driving around town\n",
            "whelp gonna crash roll another coin please stop laughing okay\n",
            "guys finish last ditch ditch sign calling him dummy momma\n",
            "tried to find her sonbut guess who died young hey\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taylor Swift Songs"
      ],
      "metadata": {
        "id": "ebDTuPPt4ZmR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1UE_Q_GsYOh"
      },
      "source": [
        "We will now create some Taylor Swift songs through our own GPT model. Let's define a GPT class using all of the material we learned so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji3UY_16sLYy"
      },
      "outputs": [],
      "source": [
        "class GPT(nn.Module):\n",
        "    \"\"\"\n",
        "    A GPT-like transformer model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    vocab_size : int\n",
        "        The size of the vocabulary.\n",
        "    context_length : int\n",
        "        The length of the input context.\n",
        "    model_dim : int\n",
        "        The dimensionality of the model.\n",
        "    num_blocks : int\n",
        "        The number of transformer blocks.\n",
        "    num_heads : int\n",
        "        The number of attention heads.\n",
        "    \"\"\"\n",
        "    class TransformerBlock(nn.Module):\n",
        "        \"\"\"\n",
        "        A single transformer block consisting of multi-headed self-attention\n",
        "        and a feedforward neural network.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        model_dim : int\n",
        "            The dimensionality of the model.\n",
        "        num_heads : int\n",
        "            The number of attention heads.\n",
        "        \"\"\"\n",
        "        class MultiHeadedSelfAttention(nn.Module):\n",
        "            \"\"\"\n",
        "            Multi-headed self-attention mechanism.\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "            model_dim : int\n",
        "                The dimensionality of the model.\n",
        "            num_heads : int\n",
        "                The number of attention heads.\n",
        "            \"\"\"\n",
        "            class SingleHeadAttention(nn.Module):\n",
        "                \"\"\"\n",
        "                Single head attention mechanism.\n",
        "\n",
        "                Parameters\n",
        "                ----------\n",
        "                model_dim : int\n",
        "                    The dimensionality of the model.\n",
        "                head_size : int\n",
        "                    The size of each attention head.\n",
        "                \"\"\"\n",
        "                def __init__(self, model_dim: int, head_size: int):\n",
        "                    super().__init__()\n",
        "                    self.key_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "                    self.query_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "                    self.value_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "\n",
        "                def forward(self, embedded):\n",
        "                    \"\"\"\n",
        "                    Forward pass for single-head self-attention.\n",
        "\n",
        "                    Parameters\n",
        "                    ----------\n",
        "                    embedded : torch.Tensor\n",
        "                        The input tensor of shape (batch_size, context_length, model_dim).\n",
        "\n",
        "                    Returns\n",
        "                    -------\n",
        "                    torch.Tensor\n",
        "                        The attention-weighted values.\n",
        "                    \"\"\"\n",
        "                    k = self.key_layer(embedded)\n",
        "                    q = self.query_layer(embedded)\n",
        "                    v = self.value_layer(embedded)\n",
        "\n",
        "                    scores = q @ torch.transpose(k, 1, 2)  # Compute attention scores\n",
        "                    context_length, attention_dim = k.shape[1], k.shape[2]\n",
        "                    scores = scores / (attention_dim ** 0.5)  # Scale scores\n",
        "\n",
        "                    # Create a lower triangular mask for causal attention\n",
        "                    lower_triangular = torch.tril(torch.ones(context_length, context_length))\n",
        "                    mask = (lower_triangular == 0).to(device)\n",
        "                    scores = scores.masked_fill(mask, float('-inf'))\n",
        "                    scores = nn.functional.softmax(scores, dim=2)\n",
        "\n",
        "                    return scores @ v  # Weighted sum of values\n",
        "\n",
        "            def __init__(self, model_dim: int, num_heads: int):\n",
        "                super().__init__()\n",
        "                self.attention_heads = nn.ModuleList()\n",
        "                for _ in range(num_heads):\n",
        "                    self.attention_heads.append(self.SingleHeadAttention(model_dim, model_dim // num_heads))\n",
        "                self.compute = nn.Linear(model_dim, model_dim)\n",
        "                self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "            def forward(self, embedded):\n",
        "                \"\"\"\n",
        "                Forward pass for multi-headed self-attention.\n",
        "\n",
        "                Parameters\n",
        "                ----------\n",
        "                embedded : torch.Tensor\n",
        "                    The input tensor of shape (batch_size, context_length, model_dim).\n",
        "\n",
        "                Returns\n",
        "                -------\n",
        "                torch.Tensor\n",
        "                    The output tensor after multi-headed attention.\n",
        "                \"\"\"\n",
        "                head_outputs = [head(embedded) for head in self.attention_heads]\n",
        "                concatenated = torch.cat(head_outputs, dim=2)\n",
        "                return self.dropout(self.compute(concatenated))\n",
        "\n",
        "        class VanillaNeuralNetwork(nn.Module):\n",
        "            \"\"\"\n",
        "            A simple feedforward neural network used within the transformer block.\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "            model_dim : int\n",
        "                The dimensionality of the model.\n",
        "            \"\"\"\n",
        "            def __init__(self, model_dim: int):\n",
        "                super().__init__()\n",
        "                self.first_linear_layer = nn.Linear(model_dim, model_dim * 4)\n",
        "                self.relu = nn.ReLU()\n",
        "                self.second_linear_layer = nn.Linear(model_dim * 4, model_dim)\n",
        "                self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "            def forward(self, x):\n",
        "                \"\"\"\n",
        "                Forward pass for the feedforward network.\n",
        "\n",
        "                Parameters\n",
        "                ----------\n",
        "                x : torch.Tensor\n",
        "                    Input tensor.\n",
        "\n",
        "                Returns\n",
        "                -------\n",
        "                torch.Tensor\n",
        "                    Output tensor.\n",
        "                \"\"\"\n",
        "                return self.dropout(self.second_linear_layer(self.relu(self.first_linear_layer(x))))\n",
        "\n",
        "        def __init__(self, model_dim: int, num_heads: int):\n",
        "            super().__init__()\n",
        "            self.mhsa = self.MultiHeadedSelfAttention(model_dim, num_heads)\n",
        "            self.vanilla_nn = self.VanillaNeuralNetwork(model_dim)\n",
        "            self.layer_norm_one = nn.LayerNorm(model_dim)\n",
        "            self.layer_norm_two = nn.LayerNorm(model_dim)\n",
        "\n",
        "        def forward(self, embedded):\n",
        "            \"\"\"\n",
        "            Forward pass for the transformer block.\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "            embedded : torch.Tensor\n",
        "                Input tensor.\n",
        "\n",
        "            Returns\n",
        "            -------\n",
        "            torch.Tensor\n",
        "                Processed tensor.\n",
        "            \"\"\"\n",
        "            embedded = embedded + self.mhsa(self.layer_norm_one(embedded))  # Skip connection\n",
        "            embedded = embedded + self.vanilla_nn(self.layer_norm_two(embedded))  # Another skip connection\n",
        "            return embedded\n",
        "\n",
        "    def __init__(self, vocab_size: int, context_length: int, model_dim: int, num_blocks: int, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, model_dim)\n",
        "        self.pos_embedding = nn.Embedding(context_length, model_dim)\n",
        "        self.transformer_blocks = nn.Sequential(*[self.TransformerBlock(model_dim, num_heads) for _ in range(num_blocks)])\n",
        "        self.layer_norm_three = nn.LayerNorm(model_dim)\n",
        "        self.vocab_projection = nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "    def forward(self, context):\n",
        "        \"\"\"\n",
        "        Forward pass for the GPT model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        context : torch.Tensor\n",
        "            Input tensor of token indices.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The logits for the next token prediction.\n",
        "        \"\"\"\n",
        "        embedded = self.token_embedding(context)\n",
        "        context_length = context.shape[1]\n",
        "        positions = torch.arange(context_length).to(device)\n",
        "        embedded = embedded + self.pos_embedding(positions)\n",
        "\n",
        "        raw_output = self.vocab_projection(self.layer_norm_three(self.transformer_blocks(embedded)))\n",
        "        return raw_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then load and preprocess lyric data."
      ],
      "metadata": {
        "id": "jakm4OKxLrwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the file content\n",
        "with open('/content/TaylorLyrics.txt', 'r', encoding='utf-8') as f:\n",
        "    lyrics = f.read()"
      ],
      "metadata": {
        "id": "PbVM6tFdLm4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we a create character-level vocabulary."
      ],
      "metadata": {
        "id": "IHilimZmPYnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars = sorted(set(lyrics))\n",
        "char_to_int = {ch: i for i, ch in enumerate(unique_chars)}\n",
        "int_to_char = {i: ch for ch, i in char_to_int.items()}"
      ],
      "metadata": {
        "id": "d22akECHPYCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And encode the lyrics data."
      ],
      "metadata": {
        "id": "1lahpG9NPc81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_lyrics = [char_to_int[ch] for ch in lyrics]"
      ],
      "metadata": {
        "id": "K-kC61c3PfAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also prepare input-target sequences."
      ],
      "metadata": {
        "id": "GurhJ-UbPghf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, seq_length):\n",
        "    \"\"\"Generates input-target sequences from a dataset for training.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : list or numpy.ndarray\n",
        "        Input data from which sequences are generated.\n",
        "    seq_length : int\n",
        "        Length of each input sequence.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple of torch.Tensor\n",
        "        A tuple (inputs, targets), where:\n",
        "        - inputs: Tensor of shape (num_samples, seq_length) representing input sequences.\n",
        "        - targets: Tensor of shape (num_samples, seq_length) representing target sequences.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - Each input sequence consists of `seq_length` consecutive elements from the input data.\n",
        "    - Each target sequence is the corresponding next `seq_length` elements, offset by one.\n",
        "    - Useful for training sequence models like RNNs or Transformers.\n",
        "    \"\"\"\n",
        "    inputs, targets = [], []  # Initialize lists to store input and target sequences.\n",
        "\n",
        "    # Iterate through the data to extract sequences.\n",
        "    for i in range(len(data) - seq_length):\n",
        "        inputs.append(data[i:i + seq_length])  # Input sequence of length `seq_length`.\n",
        "        targets.append(data[i + 1:i + seq_length + 1])  # Corresponding target sequence.\n",
        "\n",
        "    # Convert lists to tensors for use with PyTorch models.\n",
        "    return torch.tensor(inputs), torch.tensor(targets)\n",
        "\n",
        "seq_length = 128\n",
        "X_train, y_train = create_sequences(encoded_lyrics, seq_length)"
      ],
      "metadata": {
        "id": "CGPIwgKYPhzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' Number of sequences in training data: {len(X_train)}')"
      ],
      "metadata": {
        "id": "H-07kKQPZjf6",
        "outputId": "6fd72ea6-db38-45f6-e5cc-e14f306eecb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Number of sequences in training data: 278642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And train the model by using a subset of all available song text."
      ],
      "metadata": {
        "id": "y5LJ9z_bPnwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_size = 10_000\n",
        "X_train, y_train = X_train[:subset_size], y_train[:subset_size]\n",
        "\n",
        "# Batch size and training epochs\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "# Initialize model and optimizer\n",
        "model = GPT(vocab_size=len(unique_chars), context_length=128, model_dim=252, num_blocks=6, num_heads=6).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# AMP API\n",
        "scaler = torch.amp.GradScaler()\n",
        "\n",
        "# Training loop with batching and mixed precision\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        context = X_train[i:i + batch_size].to(device)\n",
        "        target = y_train[i:i + batch_size].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast(\"cuda\"):\n",
        "            output = model(context)\n",
        "            loss = criterion(output.view(-1, len(unique_chars)), target.view(-1))\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / (len(X_train) // batch_size)}\")\n",
        "\n",
        "# Save the improved model\n",
        "torch.save(model.state_dict(), 'taylor_swift_tuned_weights.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBxUcI6fPoT_",
        "outputId": "60493d31-79ab-4163-f2bb-265b126c5206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.8765149208215566\n",
            "Epoch 2, Loss: 2.5246675381293664\n",
            "Epoch 3, Loss: 2.461440086364746\n",
            "Epoch 4, Loss: 2.4223521397664\n",
            "Epoch 5, Loss: 2.3872444262871375\n",
            "Epoch 6, Loss: 2.344626871439127\n",
            "Epoch 7, Loss: 2.2772603310071506\n",
            "Epoch 8, Loss: 2.1744229961664248\n",
            "Epoch 9, Loss: 2.058120913994618\n",
            "Epoch 10, Loss: 1.9431725113819807\n",
            "Epoch 11, Loss: 1.827827050135686\n",
            "Epoch 12, Loss: 1.7117471175316052\n",
            "Epoch 13, Loss: 1.5888461669286091\n",
            "Epoch 14, Loss: 1.4607404898374508\n",
            "Epoch 15, Loss: 1.3378432866854546\n",
            "Epoch 16, Loss: 1.2253655997606425\n",
            "Epoch 17, Loss: 1.1202915494258587\n",
            "Epoch 18, Loss: 1.0049482954618258\n",
            "Epoch 19, Loss: 0.8862171387061094\n",
            "Epoch 20, Loss: 0.7867188285558652\n",
            "Epoch 21, Loss: 0.6935804948592798\n",
            "Epoch 22, Loss: 0.6094872997357295\n",
            "Epoch 23, Loss: 0.5407178201354467\n",
            "Epoch 24, Loss: 0.49186816868873745\n",
            "Epoch 25, Loss: 0.43516856279128635\n",
            "Epoch 26, Loss: 0.37898659591491407\n",
            "Epoch 27, Loss: 0.33241895825052875\n",
            "Epoch 28, Loss: 0.29611976482929325\n",
            "Epoch 29, Loss: 0.256783599845874\n",
            "Epoch 30, Loss: 0.22228326046696076\n",
            "Epoch 31, Loss: 0.19907760247588158\n",
            "Epoch 32, Loss: 0.17864639885150468\n",
            "Epoch 33, Loss: 0.15929992420551103\n",
            "Epoch 34, Loss: 0.14579042668143907\n",
            "Epoch 35, Loss: 0.1354434886135352\n",
            "Epoch 36, Loss: 0.12705802124662277\n",
            "Epoch 37, Loss: 0.12084611619894321\n",
            "Epoch 38, Loss: 0.11463778322705856\n",
            "Epoch 39, Loss: 0.10847964147344613\n",
            "Epoch 40, Loss: 0.10359500219615606\n",
            "Epoch 41, Loss: 0.10026286036158219\n",
            "Epoch 42, Loss: 0.09678939586648574\n",
            "Epoch 43, Loss: 0.09515279779831569\n",
            "Epoch 44, Loss: 0.09259258712140414\n",
            "Epoch 45, Loss: 0.09125960059463978\n",
            "Epoch 46, Loss: 0.08877438913362148\n",
            "Epoch 47, Loss: 0.08748026015475774\n",
            "Epoch 48, Loss: 0.08605815833195662\n",
            "Epoch 49, Loss: 0.08487439781236343\n",
            "Epoch 50, Loss: 0.08340245547393958\n",
            "Epoch 51, Loss: 0.08136429460958028\n",
            "Epoch 52, Loss: 0.08132547187881592\n",
            "Epoch 53, Loss: 0.07944419172902902\n",
            "Epoch 54, Loss: 0.07975439536265838\n",
            "Epoch 55, Loss: 0.07861160529920688\n",
            "Epoch 56, Loss: 0.07672741068288302\n",
            "Epoch 57, Loss: 0.07584879408853176\n",
            "Epoch 58, Loss: 0.0748258924159484\n",
            "Epoch 59, Loss: 0.07451541707492791\n",
            "Epoch 60, Loss: 0.07555132249417977\n",
            "Epoch 61, Loss: 0.07991080115047786\n",
            "Epoch 62, Loss: 0.08211220017610452\n",
            "Epoch 63, Loss: 0.08370686714083721\n",
            "Epoch 64, Loss: 0.10616476685763934\n",
            "Epoch 65, Loss: 0.14929066073053923\n",
            "Epoch 66, Loss: 0.15503795454517388\n",
            "Epoch 67, Loss: 0.12348708476966773\n",
            "Epoch 68, Loss: 0.099577685770316\n",
            "Epoch 69, Loss: 0.08072404730587433\n",
            "Epoch 70, Loss: 0.07500791974747792\n",
            "Epoch 71, Loss: 0.07223816884633823\n",
            "Epoch 72, Loss: 0.06988076354639652\n",
            "Epoch 73, Loss: 0.06797460586023636\n",
            "Epoch 74, Loss: 0.06729259060170406\n",
            "Epoch 75, Loss: 0.06653392787736195\n",
            "Epoch 76, Loss: 0.0661431520890731\n",
            "Epoch 77, Loss: 0.06495248612303\n",
            "Epoch 78, Loss: 0.0643484525095958\n",
            "Epoch 79, Loss: 0.06423121561797765\n",
            "Epoch 80, Loss: 0.06464426792584933\n",
            "Epoch 81, Loss: 0.06432745959132145\n",
            "Epoch 82, Loss: 0.06356051831673352\n",
            "Epoch 83, Loss: 0.06329155130646168\n",
            "Epoch 84, Loss: 0.06313058805580322\n",
            "Epoch 85, Loss: 0.0629103374786866\n",
            "Epoch 86, Loss: 0.06367307476317272\n",
            "Epoch 87, Loss: 0.06280181552164066\n",
            "Epoch 88, Loss: 0.0629091210758839\n",
            "Epoch 89, Loss: 0.06317433791282849\n",
            "Epoch 90, Loss: 0.06333565616454834\n",
            "Epoch 91, Loss: 0.06259155368957764\n",
            "Epoch 92, Loss: 0.0627297211247377\n",
            "Epoch 93, Loss: 0.06279156982707672\n",
            "Epoch 94, Loss: 0.06270942330742493\n",
            "Epoch 95, Loss: 0.06218346284750181\n",
            "Epoch 96, Loss: 0.06236965963855768\n",
            "Epoch 97, Loss: 0.06186065660455288\n",
            "Epoch 98, Loss: 0.06184063398112089\n",
            "Epoch 99, Loss: 0.061712462693834916\n",
            "Epoch 100, Loss: 0.06161452433428703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create a generate lyrics function and use it to write Taylor Swift songs."
      ],
      "metadata": {
        "id": "GGb7puw3Pw_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_lyrics(model, new_chars, context, context_length, int_to_char, temperature=1.0):\n",
        "    \"\"\"Generates lyrics using a trained character-level language model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The trained language model for character generation.\n",
        "    new_chars : int\n",
        "        Number of new characters to generate.\n",
        "    context : torch.Tensor\n",
        "        Input tensor representing the initial context (shape: [1, sequence_length]).\n",
        "    context_length : int\n",
        "        Maximum length of context to retain during generation.\n",
        "    int_to_char : dict\n",
        "        Mapping from integer indices to characters.\n",
        "    temperature : float, optional\n",
        "        Sampling temperature controlling randomness. Lower values make predictions more deterministic,\n",
        "        while higher values increase diversity. Default is 1.0.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Generated lyrics as a string.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - The function performs autoregressive generation by sampling one character at a time.\n",
        "    - Uses softmax with a temperature parameter to control the randomness of predictions.\n",
        "    - Context is truncated to `context_length` to prevent memory overflow.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode (disables dropout, etc.).\n",
        "    res = []  # Store generated characters.\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for faster inference.\n",
        "        for _ in range(new_chars):\n",
        "            # Keep only the last `context_length` characters.\n",
        "            if context.shape[1] > context_length:\n",
        "                context = context[:, -context_length:]\n",
        "\n",
        "            # Forward pass: generate model output (logits).\n",
        "            output = model(context)\n",
        "\n",
        "            # Extract logits for the last time step and apply temperature scaling.\n",
        "            logits = output[:, -1, :] / temperature\n",
        "\n",
        "            # Convert logits to probabilities using softmax.\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "            # Sample the next character index from the probability distribution.\n",
        "            next_char = torch.multinomial(probs, 1)\n",
        "\n",
        "            # Append the new character to the context.\n",
        "            context = torch.cat((context, next_char), dim=-1)\n",
        "\n",
        "            # Map the character index to its corresponding character and store it.\n",
        "            res.append(int_to_char[next_char.item()])\n",
        "\n",
        "    return ''.join(res)  # Return the generated lyrics as a string."
      ],
      "metadata": {
        "id": "UQiHPinV9Ogc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"On a park bench\"\n",
        "start_context = torch.tensor([[char_to_int[c] for c in seed_text]], dtype=torch.int64).to(device)\n",
        "\n",
        "new_lyrics = generate_lyrics(model, new_chars=2000, context=start_context, context_length=128, int_to_char=int_to_char, temperature=1.0)\n",
        "print(new_lyrics)"
      ],
      "metadata": {
        "id": "NGvPU1EDP04K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b57b5f-c32a-4d6c-dd9b-fd0853217cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " he's all the song\n",
            "The the scars you ming my heart on my sleeve\n",
            "Feeling lucky today, got the sunshine\n",
            "Could you tell me what more do I need\n",
            "And tomorrow's just a mystery, oh yeah\n",
            "But that's ok\n",
            "\n",
            "[Chorus]\n",
            "\n",
            "Maybe I'm just a girl on a mission\n",
            "But I'm ready to fly\n",
            "\n",
            "I'm alone, on my own, and that's all I know\n",
            "I'll be strong, I'll be wrong, oh but life goes on\n",
            "Oh, I'm just a girl, trying to find a place in this world\n",
            "\n",
            "Got the radio on, my old blue jeans\n",
            "And I'm wearing my heart on my sleeve\n",
            "Feeling lucky today, got the sunshine\n",
            "Could you tell me what more do I need\n",
            "And tomorrow's just a mystery, oh yeah\n",
            "But that's ok\n",
            "\n",
            "[Chorus]\n",
            "\n",
            "Maybe I'm just a girl on a mission\n",
            "But I'm ready to fly\n",
            "\n",
            "I'm alone, on my own, and that's all I know\n",
            "I'll be strong, I'll be wrong, oh but life goes on\n",
            "Oh I'm alone, on my own, and that's all I know\n",
            "Oh I'm just a girl, trying to find a place in this world\n",
            "\n",
            "Oh I'm just a girl\n",
            "Oh I'm just a girl, oh, oh,\n",
            "Oh I'm just a girl\n",
            "\n",
            "You have a way of coming easily to me\n",
            "And when you take, you take the very best of me\n",
            "So I start a fight 'cause I need to feel something\n",
            "And you do what you want 'cause I'm not what you wanted\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "Just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "I didn't know what I would find\n",
            "When I went looking for a reason,\n",
            "I know I didn't read between the lines\n",
            "And, baby, I've got nowhere to go\n",
            "\n",
            "I tried to take the road less traveled by\n",
            "But nothing seems to work the first few times\n",
            "Am I right?\n",
            "\n",
            "So how can I ever try to be better?\n",
            "Nobody ever lets me in\n",
            "I can still see you.\n",
            "This ain't the best view\n",
            "On the outside looking in\n",
            "And I've been a lot of lonely places\n",
            "I've never been on the outside\n",
            "\n",
            "Oh, yeah\n",
            "\n",
            "So how can I ever try to be better?\n",
            "Nobody ever lets me in\n",
            "And I can still see you.\n",
            "This ain't the best view\n",
            "On the outside looking in\n",
            "And I've been a lot of lonely places\n",
            "I've never been on\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"In the middle of town\"\n",
        "start_context = torch.tensor([[char_to_int[c] for c in seed_text]], dtype=torch.int64).to(device)\n",
        "\n",
        "new_lyrics = generate_lyrics(model, new_chars=4000, context=start_context, context_length=128, int_to_char=int_to_char, temperature=0.8)\n",
        "print(new_lyrics)"
      ],
      "metadata": {
        "id": "udFbHuHW9RoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6097bcec-4aa1-44b9-fc32-d5e0d157d44c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", and that's all I know\n",
            "Oh I'm just a girl, trying to find a place in this world\n",
            "\n",
            "Oh I'm just a girl\n",
            "Oh I'm just a girl, oh, oh,\n",
            "Oh I'm just a girl\n",
            "\n",
            "You have a way of coming easily to me\n",
            "And when you take, you take the very best of me\n",
            "So I start a fight 'cause I need to feel something\n",
            "And you do what you want 'cause I'm not what you wanted\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "Just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You put up walls and paint them all a shade of gray\n",
            "And I stood there loving you and wished them all away\n",
            "And you come away with a great little story\n",
            "Of a mess of a dreamer with the nerve to adore you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "So, just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You put up walls and paint them all a shade of gray\n",
            "And I stood there loving you and wished them all away\n",
            "And you come away with a great little story\n",
            "Of a mess of a dreamer with the nerve to adore you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "So, just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You put up walls and paint them all a shade of gray\n",
            "And I stood there loving you and wished them all away\n",
            "And you come away with a great little story\n",
            "Of a mess of a dreamer with the nerve to adore you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "So, just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You put up walls and paint them all a shade of gray\n",
            "And I stood there loving you and wished them all away\n",
            "And you come away with a great little story\n",
            "Of a mess of a dreamer with the nerve to adore you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "So, just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You put up walls and paint them all a shade of gray\n",
            "And I stood there loving you and wished them all away\n",
            "And you come away with a great little story\n",
            "Of a mess of a dreamer with the nerve to adore you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "So, just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You put up walls and paint them all a shade of gray\n",
            "And I stood there loving you and wished them all away\n",
            "And you come away with a great little story\n",
            "Of a mess of a dreamer with the nerve to adore you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "So, just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You put up walls and paint them all a shade of gray\n",
            "And I stood there loving you and wished them all away\n",
            "And you come away with a great little story\n",
            "Of a mess of a dreamer with the nerve to adore you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "So, just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You never did give a damn thing, honey, but I cried, cried for you\n",
            "And I know you wouldn't have told nobody if I died, died for you, died for you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "Every smile you fake is so condescending counting all the scars you made\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "I didn't know what I would find\n",
            "When I went looking for a reason,\n",
            "I know I didn't read between the lines\n",
            "And, baby, I've got nowhere to go\n",
            "\n",
            "I tried to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"I found the perfect pair of shoes\"\n",
        "start_context = torch.tensor([[char_to_int[c] for c in seed_text]], dtype=torch.int64).to(device)\n",
        "\n",
        "new_lyrics = generate_lyrics(model, new_chars=4000, context=start_context, context_length=128, int_to_char=int_to_char, temperature=0.8)\n",
        "print(new_lyrics)"
      ],
      "metadata": {
        "id": "6zSMujo73S_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f848d474-972d-427a-bdbb-3b4547b17973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s\n",
            "And I'm just a girl, oh, oh,\n",
            "Oh I'm just a girl\n",
            "\n",
            "You have a way of coming easily to me\n",
            "And when you take, you take the very best of me\n",
            "So I start a fight 'cause I need to feel something\n",
            "And you do what you want 'cause I'm not what you wanted\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "Just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You put up walls and paint them all a shade of gray\n",
            "And I stood there loving you and wished them all away\n",
            "And you come away with a great little story\n",
            "Of a mess of a dreamer with the nerve to adore you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "So, just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You put up walls and paint them all a shade of gray\n",
            "And I stood there loving you and wished them all away\n",
            "And you come away with a great little story\n",
            "Of a mess of a dreamer with the nerve to adore you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "So, just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "You put up walls and paint them all a shade of gray\n",
            "And I stood there loving you and wished them all away\n",
            "And you come away with a great little story\n",
            "Of a mess of a dreamer with the nerve to adore you\n",
            "\n",
            "Oh, what a shame, what a rainy ending given to a perfect day\n",
            "So, just walk away, no use defending words that you will never say\n",
            "And now that I'm sitting here thinking it through\n",
            "I've never been anywhere cold as you\n",
            "\n",
            "I didn't know what I would find\n",
            "When I went looking for a reason,\n",
            "I know I didn't read between the lines\n",
            "And, baby, I've got nowhere to go\n",
            "\n",
            "I tried to take the road less traveled by\n",
            "But nothing seems to work the first few times\n",
            "Am I right?\n",
            "\n",
            "So how can I ever try to be better?\n",
            "Nobody ever lets me in\n",
            "I can still see you.\n",
            "This ain't the best view\n",
            "On the outside looking in\n",
            "And I've been a lot of lonely places\n",
            "I've never been on the outside\n",
            "\n",
            "Seems the only one who doesn't see your beauty\n",
            "Is the face in the mirror looking back at you\n",
            "You walk around here thinking you're not pretty\n",
            "But that's not true 'cause I know you\n",
            "\n",
            "Hold on, baby, you're losing it\n",
            "The water's high, you're jumping into it\n",
            "And letting go\n",
            "And no one knows\n",
            "That you cry, but you don't tell anyone\n",
            "That you might not be the golden one\n",
            "And you're tied together with a smile\n",
            "But you're coming undone\n",
            "\n",
            "I guess it's true that love was all you wanted\n",
            "'Cause you're giving it away like it's extra change\n",
            "Hoping it will end up in his pocket\n",
            "But he leaves you out like a penny in the rain\n",
            "\n",
            "Oh, 'cause it's not his price to pay\n",
            "It's not his price to pay\n",
            "\n",
            "Hold on, baby, you're losing it\n",
            "The water's high, you're jumping into it\n",
            "And letting go\n",
            "And no one knows\n",
            "That you cry, but you don't tell anyone\n",
            "That you might not be the golden one\n",
            "And you're tied together with a smile\n",
            "But you're coming undone\n",
            "\n",
            "Hold on, baby, you're losing it\n",
            "The water's high, you're jumping into it\n",
            "And letting go\n",
            "And no one knows\n",
            "That you cry, but you don't tell anyone\n",
            "That you might not be the golden one\n",
            "And you're tied together with a smile\n",
            "But you're coming undone\n",
            "\n",
            "You're tied together with a smile\n",
            "But you're coming undone\n",
            "Goodbye, baby\n",
            "With a smile, baby, baby\n",
            "\n",
            "Cory's eyes are like a jungle\n",
            "He smiles, it's like the radio\n",
            "He whispers songs into my window\n",
            "In words that nobody knows\n",
            "There's pretty girls on every corner\n",
            "That watch him as he's walking home\n",
            "Saying, \"Does he know?\"\n",
            "Will you ever know?\n",
            "\n",
            "[Chorus:]\n",
            "You're beautiful\n",
            "Every little piece love\n",
            "And don't you know\n",
            "You're really gonna be someone\n",
            "Ask anyone\n",
            "And when you find everything you looked for\n",
            "I hope your life leads you back to my door\n",
            "Oh, but if it don't\n",
            "Stay beautiful\n",
            "\n",
            "Cory finds another way to be\n",
            "The highlight of my day\n",
            "I'm taking pictures in my mind\n",
            "So I can save them for a r\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5479e124f5d54fcca35eda5ead3ad565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0af8a04ba85410fafa8977c155d2099",
              "IPY_MODEL_0cf652af0eb44def9de04bd3c135bf2b",
              "IPY_MODEL_7d56fb8a02f1498d9987b5cf9082249b"
            ],
            "layout": "IPY_MODEL_bcecc9c8b44f482c8c3e01b02d29f636"
          }
        },
        "d0af8a04ba85410fafa8977c155d2099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caa13203146d483fbe93f61e1b91b611",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d04a5ce4f9f543dcb40fe2dc7e2d7b7e",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "0cf652af0eb44def9de04bd3c135bf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1382297b054ee68e1f289d1af41aa7",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdcb28cc549f4af49805695dcebb00c9",
            "value": 548105171
          }
        },
        "7d56fb8a02f1498d9987b5cf9082249b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db81457b9334036a371b930cff2a1a3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_80ce7f4eb3794d0fae591f02dc8ec34f",
            "value": "â€‡548M/548Mâ€‡[00:05&lt;00:00,â€‡38.8MB/s]"
          }
        },
        "bcecc9c8b44f482c8c3e01b02d29f636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa13203146d483fbe93f61e1b91b611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d04a5ce4f9f543dcb40fe2dc7e2d7b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c1382297b054ee68e1f289d1af41aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdcb28cc549f4af49805695dcebb00c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3db81457b9334036a371b930cff2a1a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80ce7f4eb3794d0fae591f02dc8ec34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f6d854b8fa1490aadbb8d5eb5776504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bcc57393c5e4391bfa075f6df83d54e",
              "IPY_MODEL_2bcf3d13234d4fa0be4279ac487d871c",
              "IPY_MODEL_d57952ab796d40c084a7a640e2fee268"
            ],
            "layout": "IPY_MODEL_3497229640b84840bd2b44ba44676a2b"
          }
        },
        "0bcc57393c5e4391bfa075f6df83d54e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8ccb02fb804257a9843109218846da",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3f45e8f8f7564610822abb1b455cc92e",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "2bcf3d13234d4fa0be4279ac487d871c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a8e0671bc3849b1be2bece25dd6b9d3",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4287abb80d9248dbbff29f07d7aa497a",
            "value": 124
          }
        },
        "d57952ab796d40c084a7a640e2fee268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_599f5061c6ea4ff6b7c1b7fbf5586fc5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ccf9aac32ec54a939852b08d4bd24947",
            "value": "â€‡124/124â€‡[00:00&lt;00:00,â€‡10.7kB/s]"
          }
        },
        "3497229640b84840bd2b44ba44676a2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d8ccb02fb804257a9843109218846da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f45e8f8f7564610822abb1b455cc92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a8e0671bc3849b1be2bece25dd6b9d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4287abb80d9248dbbff29f07d7aa497a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "599f5061c6ea4ff6b7c1b7fbf5586fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf9aac32ec54a939852b08d4bd24947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c89601e3b37448d9303ce52e98135aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_831c8e2828e5428ca25f3c556050857c"
          }
        },
        "7651f65c62864fb88eb8ddb8cc29b8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9900ed713c0444da992a570e4c3c6e0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_44993270eb244f8bb0897e23632fb27e",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e8aafb6aeb7a4f1096882504ba13aef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_19ef806a7d904e29a1786e08b073db19",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f3fc7768827a4e6e90d0809fd5f89a32",
            "value": ""
          }
        },
        "5a18fa9dc99a4ac8ad8319b4a193cfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_84d302a6518d4dba8d6dbddbb7198bf4",
            "style": "IPY_MODEL_73789d9b4bc94744852755b5a276f2b4",
            "value": true
          }
        },
        "550e69568853423c9f047845ac90b5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9820eec0a0014e73a3c20f25590f7b91",
            "style": "IPY_MODEL_991d327d572f483893b1ed5f2a34d609",
            "tooltip": ""
          }
        },
        "9b821fe2635744e1b3ea95c7e0576c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5104c7becb744e9ca9a59806db211df6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_da80f96ffd5e466d81cd886f6a1f92e9",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "831c8e2828e5428ca25f3c556050857c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "d9900ed713c0444da992a570e4c3c6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44993270eb244f8bb0897e23632fb27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19ef806a7d904e29a1786e08b073db19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3fc7768827a4e6e90d0809fd5f89a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84d302a6518d4dba8d6dbddbb7198bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73789d9b4bc94744852755b5a276f2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9820eec0a0014e73a3c20f25590f7b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991d327d572f483893b1ed5f2a34d609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5104c7becb744e9ca9a59806db211df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da80f96ffd5e466d81cd886f6a1f92e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef5322aca035455ba9db87a9576431a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63cb571ddb014b50a24b771e7c4c29e8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e8bcd70323e1420eb839db62fd0e82d6",
            "value": "Connecting..."
          }
        },
        "63cb571ddb014b50a24b771e7c4c29e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8bcd70323e1420eb839db62fd0e82d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}